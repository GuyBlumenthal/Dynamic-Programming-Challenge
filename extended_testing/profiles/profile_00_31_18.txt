Timer unit: 1e-07 s

Total time: 0.240701 s
Function: solution at line 31

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    31                                           def solution(C: Const) -> tuple[np.ndarray, np.ndarray]:
    32                                               # 1. Setup Phase
    33                                               # -----------------------------------------------------
    34         1         89.0     89.0      0.0      Total_start = time.perf_counter()
    35         1        930.0    930.0      0.0      print("Computing Transition Probabilities... (Optimized Hashing)")
    36                                               
    37         1         35.0     35.0      0.0      T_start = time.perf_counter()
    38                                               
    39                                               # 1. Compute P matrices (Fastest method: Coordinate Hashing)
    40         1     247816.0 247816.0     10.3      P_list = compute_transition_probabilities_vectorized(C)
    41                                               
    42                                               # 2. Stack them vertically: [P_action0; P_action1; ...]
    43                                               # Shape becomes (L * K, K)
    44                                               # This allows us to extract the specific row for (state k, action u) 
    45                                               # using a single efficient slice operation later.
    46         1       5573.0   5573.0      0.2      P_stack = sp.vstack(P_list).tocsr()
    47                                               
    48         1         36.0     36.0      0.0      T_end = time.perf_counter()
    49                                           
    50         1       3916.0   3916.0      0.2      print("Computing Stage Costs...")
    51         1       3638.0   3638.0      0.2      Q = compute_expected_stage_cost_fast(C, C.K)
    52                                               
    53                                               # 2. Solver Parameters
    54                                               # -----------------------------------------------------
    55         1        325.0    325.0      0.0      K, L = C.K, C.L
    56         1         34.0     34.0      0.0      gamma = 1.0
    57         1         56.0     56.0      0.0      dtype = np.float64
    58                                               
    59                                               # Initialization
    60         1        815.0    815.0      0.0      J = np.zeros(K, dtype=dtype)
    61         1        373.0    373.0      0.0      policy = np.zeros(K, dtype=int)
    62                                               
    63                                               # Pre-allocate indices for slicing
    64         1        558.0    558.0      0.0      range_k = np.arange(K, dtype=int)
    65                                               
    66                                               # Pre-build Identity matrix
    67         1       5288.0   5288.0      0.2      I_mat = sp.eye(K, format='csr', dtype=dtype)
    68                                           
    69                                               # Tuning for GMRES speed
    70         1         12.0     12.0      0.0      max_outer_iters = 200
    71         1          9.0      9.0      0.0      outer_tol = 1e-7
    72         1         10.0     10.0      0.0      gmres_tol_max = 1e-4
    73         1          6.0      6.0      0.0      gmres_tol_min = 1e-9
    74         1          9.0      9.0      0.0      gmres_restart = 60
    75         1          9.0      9.0      0.0      max_inner_iters = 30  # Keep high to minimize restarts
    76                                           
    77         1          7.0      7.0      0.0      delta_J_prev = 1.0
    78                                               
    79         1         29.0     29.0      0.0      solve_start = time.perf_counter()
    80                                           
    81                                               # 3. Policy Iteration Loop
    82                                               # -----------------------------------------------------
    83        23        220.0      9.6      0.0      for outer_iter in range(max_outer_iters):
    84        23       2288.0     99.5      0.1          J_prev = J.copy()
    85                                           
    86                                                   # --- A. Optimized Matrix Construction (Slicing) ---
    87                                                   # Goal: Construct A = I - gamma * P_pi
    88                                                   # Method: Row Slicing (Fancy Indexing) on P_stack
    89                                                   #
    90                                                   # Logic: P_stack has structure:
    91                                                   # Rows 0 to K-1: Action 0
    92                                                   # Rows K to 2K-1: Action 1
    93                                                   # ...
    94                                                   # Therefore, the row for state k taking action policy[k] is at:
    95                                                   # index = policy[k] * K + k
    96                                                   
    97        23       7589.0    330.0      0.3          selection_indices = policy * K + range_k
    98                                                   
    99                                                   # This slice is heavily optimized in Scipy (C-level copy of rows)
   100        23     166749.0   7250.0      6.9          P_pi = P_stack[selection_indices, :]
   101                                                   
   102                                                   # A = I - gamma * P_pi
   103        23     199394.0   8669.3      8.3          A_sparse = I_mat - gamma * P_pi
   104                                           
   105                                                   # --- B. Preconditioner ---
   106                                                   # A simple preconditioner speeds up GMRES significantly
   107        23      43034.0   1871.0      1.8          M_precond = make_preconditioner(A_sparse, omega=0.8, inner_iters=3, dtype=dtype)
   108                                           
   109                                                   # --- C. Right-Hand Side ---
   110        23      18315.0    796.3      0.8          b = Q[range_k, policy].astype(dtype)
   111                                           
   112                                                   # --- D. Adaptive Tolerance ---
   113                                                   # Relax tolerance when error is high to save time
   114        23        241.0     10.5      0.0          if outer_iter > 0:
   115        22        419.0     19.0      0.0              tol_k = 0.5 * delta_J_prev 
   116                                                   else:
   117         1         10.0     10.0      0.0              tol_k = gmres_tol_max
   118        23        660.0     28.7      0.0          tol_k = min(max(tol_k, gmres_tol_min), gmres_tol_max)
   119                                           
   120                                                   # --- E. Linear Solve (GMRES) ---
   121        23        151.0      6.6      0.0          try:
   122        46    1566815.0  34061.2     65.1              J_eval, info = spla.gmres(
   123        23        170.0      7.4      0.0                  A_sparse, b, x0=J, 
   124        23        118.0      5.1      0.0                  tol=tol_k, 
   125        23        117.0      5.1      0.0                  restart=gmres_restart, 
   126        23        115.0      5.0      0.0                  maxiter=max_inner_iters, 
   127        23        104.0      4.5      0.0                  M=M_precond
   128                                                       )
   129        23        364.0     15.8      0.0              if info != 0:
   130                                                           J_eval = spla.spsolve(A_sparse, b)
   131                                                   except Exception:
   132                                                       J_eval = spla.spsolve(A_sparse, b)
   133                                           
   134                                                   # --- F. Policy Improvement ---
   135                                                   # Compute Expected Future Costs for ALL actions simultaneously
   136                                                   # P_stack.dot(J) calculates [P_0*J, P_1*J] in one go.
   137        23      28875.0   1255.4      1.2          P_J_all = P_stack.dot(J_eval)
   138                                                   
   139                                                   # Reshape to (L, K) -> Transpose to (K, L) to get Q values
   140        23       1348.0     58.6      0.1          future_costs = P_J_all.reshape((L, K)).T
   141                                                   
   142        23      27096.0   1178.1      1.1          Q_J = Q + gamma * future_costs
   143                                                   
   144                                                   # Greedy Update
   145        23      40918.0   1779.0      1.7          new_policy = np.argmin(Q_J, axis=1)
   146                                           
   147                                                   # --- G. Convergence Check ---
   148        23      14535.0    632.0      0.6          policy_changes = np.sum(new_policy != policy)
   149        23      10494.0    456.3      0.4          delta_J = np.max(np.abs(J_eval - J_prev))
   150                                           
   151        23        155.0      6.7      0.0          delta_J_prev = delta_J
   152        23        377.0     16.4      0.0          J = J_eval
   153        23        224.0      9.7      0.0          policy = new_policy
   154                                           
   155        23        360.0     15.7      0.0          if policy_changes == 0 and delta_J < outer_tol:
   156         1       1749.0   1749.0      0.1              print(f"Converged in {outer_iter+1} iterations.")
   157         1         31.0     31.0      0.0              break
   158                                                   
   159        22        429.0     19.5      0.0          if outer_iter == max_outer_iters - 1:
   160                                                       print("Warning: Max outer iterations reached without convergence.")
   161                                           
   162                                               # 4. Final Timing Stats
   163                                               # -----------------------------------------------------
   164         1         66.0     66.0      0.0      Total_time = time.perf_counter() - Total_start
   165         1         16.0     16.0      0.0      T_setup = T_end - T_start
   166         1         22.0     22.0      0.0      T_solve = time.perf_counter() - solve_start
   167                                               
   168         1       1341.0   1341.0      0.1      print("\n--- Timing Summary (Fixed Slicing) ---")
   169         1        841.0    841.0      0.0      print(f"Transition Setup:  {T_setup:.6f}s")
   170         1        858.0    858.0      0.0      print(f"Solver Loop:       {T_solve:.6f}s")
   171         1        814.0    814.0      0.0      print(f"Total Runtime:     {Total_time:.6f}s")
   172                                           
   173         1         18.0     18.0      0.0      return J, policy

Total time: 0.0239622 s
File: C:\Users\tobyt\OneDrive\ETH OneDrive_Personal\Master\DPOC\DPOC_Exercise\utils.py
Function: compute_transition_probabilities_vectorized at line 232

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   232                                           def compute_transition_probabilities_vectorized(C):
   233                                               """
   234                                               Optimized transition probability calculation using Coordinate Hashing.
   235                                               
   236                                               Improvements:
   237                                               1. Coordinate Hashing: Maps (y, v, d, h) -> Integer Index in O(1).
   238                                                  Replaces np.searchsorted (O(N log N)).
   239                                               2. Vectorized Physics: Strictly follows PDF dynamics (Collision, Spawning, Motion).
   240                                               """
   241                                           
   242                                               # 1. Parse State Space & Setup Hashing
   243                                               # ---------------------------------------------------------
   244         1      55931.0  55931.0     23.3      S_arr = np.array(C.state_space, dtype=np.int32)
   245         1         58.0     58.0      0.0      N = S_arr.shape[0]
   246         1         19.0     19.0      0.0      num_cols = S_arr.shape[1]
   247                                           
   248                                               # Calculate ranges and strides for Perfect Hashing
   249                                               # We map every state to a unique integer: Hash = Sum( (val - min) * stride )
   250         1       3972.0   3972.0      1.7      mins = S_arr.min(axis=0)
   251         1       3675.0   3675.0      1.5      maxs = S_arr.max(axis=0)
   252         1        358.0    358.0      0.1      ranges = maxs - mins + 1
   253                                               
   254                                               # Compute strides (column-major-like logic, but order doesn't matter as long as consistent)
   255         1         96.0     96.0      0.0      strides = np.zeros(num_cols, dtype=np.int64)
   256         1         13.0     13.0      0.0      current_stride = 1
   257         7        121.0     17.3      0.1      for i in range(num_cols):
   258         6        113.0     18.8      0.0          strides[i] = current_stride
   259         6        161.0     26.8      0.1          current_stride *= ranges[i]
   260                                           
   261                                               # Total size of the dense lookup table
   262         1         10.0     10.0      0.0      table_size = current_stride
   263                                               
   264                                               # Safety Check: If table is > 100MB (approx 25M entries), warn or fallback.
   265                                               # For Flappy Bird, table_size is usually < 5,000,000 (20MB), which is fine.
   266                                               
   267                                               # Create the lookup table
   268                                               # lookup_table[hash] = index_in_state_space
   269         1       4406.0   4406.0      1.8      lookup_table = np.full(table_size, -1, dtype=np.int32)
   270                                               
   271                                               # Compute hashes for all existing valid states
   272                                               # Formula: sum((S_arr[:, i] - mins[i]) * strides[i])
   273         1       5878.0   5878.0      2.5      state_hashes = np.dot((S_arr - mins), strides)
   274         1        694.0    694.0      0.3      lookup_table[state_hashes] = np.arange(N, dtype=np.int32)
   275                                           
   276                                               # Helper for O(1) Lookup
   277         1         56.0     56.0      0.0      def get_state_indices(next_states):
   278                                                   # 1. Check bounds (vectorized)
   279                                                   # Any state component outside [min, max] is invalid
   280                                                   valid_bounds = np.all((next_states >= mins) & (next_states <= maxs), axis=1)
   281                                                   
   282                                                   indices = np.full(next_states.shape[0], -1, dtype=np.int32)
   283                                                   
   284                                                   if np.any(valid_bounds):
   285                                                       # 2. Compute Hashes
   286                                                       # Subset only valid bounds to avoid overflow/segfaults on hash calculation
   287                                                       valid_states = next_states[valid_bounds]
   288                                                       hashes = np.dot((valid_states - mins), strides)
   289                                                       
   290                                                       # 3. Lookup
   291                                                       # Since we checked bounds, hashes are guaranteed < table_size
   292                                                       found_indices = lookup_table[hashes]
   293                                                       indices[valid_bounds] = found_indices
   294                                                       
   295                                                   # Return indices and a boolean mask of which ones were found
   296                                                   mask_found = (indices != -1)
   297                                                   return indices[mask_found], mask_found
   298                                           
   299                                               # 2. Pre-process State Columns
   300                                               # ---------------------------------------------------------
   301         1         47.0     47.0      0.0      Y = S_arr[:, 0]
   302         1         23.0     23.0      0.0      V = S_arr[:, 1]
   303         1        156.0    156.0      0.1      D = S_arr[:, 2 : 2 + C.M]
   304         1         74.0     74.0      0.0      H = S_arr[:, 2 + C.M : 2 + 2 * C.M]
   305                                           
   306                                               # Collision Logic (PDF: "transition to a cost-free termination state")
   307                                               # We treat these as absorbing (rows of 0 in P), effectively removing them from the game flow.
   308         1         36.0     36.0      0.0      if C.M > 0:
   309         1         14.0     14.0      0.0          gap_tol = (C.G - 1) // 2
   310                                                   # Collision if inside pipe horizontally (D=0) AND outside gap vertically
   311         1       1052.0   1052.0      0.4          is_collided = (D[:, 0] == 0) & (np.abs(Y - H[:, 0]) > gap_tol)
   312                                               else:
   313                                                   is_collided = np.zeros(N, dtype=bool)
   314                                           
   315                                               # 3. Deterministic Pipe Dynamics (Pre-calculated)
   316                                               # ---------------------------------------------------------
   317         1        748.0    748.0      0.3      Hat_D = D.copy()
   318         1        713.0    713.0      0.3      Hat_H = H.copy()
   319                                           
   320         1         61.0     61.0      0.0      if C.M > 0:
   321                                                   # Mask: Pipes that are currently at x=0 (Passing/Recycling)
   322         1        185.0    185.0      0.1          mask_passing = (D[:, 0] == 0)
   323                                                   
   324                                                   # Shift pipes left
   325         1         52.0     52.0      0.0          if C.M > 1:
   326         1       1041.0   1041.0      0.4              Hat_D[mask_passing, :-1] = D[mask_passing, 1:]
   327         1        431.0    431.0      0.2              Hat_H[mask_passing, :-1] = H[mask_passing, 1:]
   328                                                   
   329                                                   # Reset last pipe (will be filled by spawn logic if applicable)
   330         1        273.0    273.0      0.1          Hat_D[mask_passing, C.M-1] = 0
   331         1         36.0     36.0      0.0          if len(C.S_h) > 0:
   332         1        223.0    223.0      0.1              Hat_H[mask_passing, C.M-1] = C.S_h[0] # Default height
   333                                           
   334                                                   # Decrement horizontal distance (Drift)
   335                                                   # Only decrement if not just reset (checked by > 0)
   336         1        112.0    112.0      0.0          mask_dec = (Hat_D[:, 0] > 0)
   337         1        761.0    761.0      0.3          Hat_D[mask_dec, 0] -= 1
   338                                           
   339                                               # Spawn Probability Logic (Linear Ramp)
   340         1       1362.0   1362.0      0.6      sum_hat_D = np.sum(Hat_D, axis=1)
   341         1         67.0     67.0      0.0      s_values = (C.X - 1) - sum_hat_D # Free space
   342                                               
   343                                               # p = (s - (Dmin-1)) / (X - Dmin)
   344         1         54.0     54.0      0.0      numerator = s_values - (C.D_min - 1)
   345         1         40.0     40.0      0.0      denominator = float(C.X - C.D_min)
   346         1        671.0    671.0      0.3      p_spawn_vec = np.clip(numerator / denominator, 0.0, 1.0)
   347                                               
   348                                               # Identify which pipe index 'k' to spawn into (first available slot)
   349         1        177.0    177.0      0.1      k_spawn_indices = np.full(N, C.M - 1, dtype=int)
   350         1         21.0     21.0      0.0      if C.M > 1:
   351                                                   # Find first column where D=0
   352         1        127.0    127.0      0.1          is_zero = (Hat_D[:, 1:] == 0)
   353         1        346.0    346.0      0.1          any_zero = np.any(is_zero, axis=1)
   354         1        644.0    644.0      0.3          first_zero = np.argmax(is_zero, axis=1)
   355         1        233.0    233.0      0.1          k_spawn_indices[any_zero] = first_zero[any_zero] + 1
   356                                           
   357                                               # 4. Input Loop & Matrix Construction
   358                                               # ---------------------------------------------------------
   359         1         19.0     19.0      0.0      prob_h_new = 1.0 / len(C.S_h) if len(C.S_h) > 0 else 0.0
   360         1         80.0     80.0      0.0      U_array = np.array(C.input_space)
   361                                               
   362         1          5.0      5.0      0.0      P_sparse_list = []
   363                                           
   364         4        114.0     28.5      0.0      for u in U_array:
   365                                                   # Initialize Coordinate Lists for Sparse Matrix
   366         3         62.0     20.7      0.0          rows_list = []
   367         3         50.0     16.7      0.0          cols_list = []
   368         3         38.0     12.7      0.0          data_list = []
   369                                                   
   370                                                   # Resolve Flap/Wind randomness
   371         3         46.0     15.3      0.0          if u == C.U_strong:
   372         1         44.0     44.0      0.0              W_flap = np.arange(-C.V_dev, C.V_dev + 1)
   373                                                   else:
   374         2         58.0     29.0      0.0              W_flap = np.array([0])
   375                                                   
   376         3         39.0     13.0      0.0          prob_flap = 1.0 / len(W_flap)
   377         3         24.0      8.0      0.0          n_w = len(W_flap)
   378                                           
   379                                                   # Vectorized Next State Calculation
   380                                                   # v_{k+1} = v_k + u + w - g
   381                                                   # Broadcast: (N, 1) + scalar + (1, n_w) -> (N, n_w)
   382         3       3135.0   1045.0      1.3          V_next_matrix = V[:, None] + u + W_flap[None, :] - C.g
   383         3        822.0    274.0      0.3          V_next_flat = np.clip(V_next_matrix, -C.V_max, C.V_max).flatten()
   384                                                   
   385                                                   # y_{k+1} = y_k + v_k (Note: Uses CURRENT v_k)
   386         3       2617.0    872.3      1.1          Y_repeated = np.repeat(Y, n_w)
   387         3       2254.0    751.3      0.9          V_curr_repeated = np.repeat(V, n_w)
   388         3       1006.0    335.3      0.4          Y_next_flat = np.clip(Y_repeated + V_curr_repeated, 0, C.Y - 1).astype(np.int32)
   389                                                   
   390                                                   # Filter Collided Sources (They don't transition)
   391         3       2622.0    874.0      1.1          source_idxs_base = np.repeat(np.arange(N), n_w)
   392         3       2705.0    901.7      1.1          valid_src_mask = ~np.repeat(is_collided, n_w)
   393                                                   
   394                                                   # Apply mask
   395         3        370.0    123.3      0.2          V_next = V_next_flat[valid_src_mask]
   396         3        536.0    178.7      0.2          Y_next = Y_next_flat[valid_src_mask]
   397         3        829.0    276.3      0.3          src_idxs = source_idxs_base[valid_src_mask]
   398                                                   
   399                                                   # Get pipe state for these sources
   400         3       5308.0   1769.3      2.2          Hat_D_sub = Hat_D[src_idxs]
   401         3       5624.0   1874.7      2.3          Hat_H_sub = Hat_H[src_idxs]
   402         3       4419.0   1473.0      1.8          p_spawn_sub = p_spawn_vec[src_idxs]
   403                                                   
   404                                                   # --- PATH A: NO SPAWN ---
   405                                                   # Prob = prob_flap * (1 - p_spawn)
   406         3       2325.0    775.0      1.0          probs_ns = prob_flap * (1.0 - p_spawn_sub)
   407         3        456.0    152.0      0.2          mask_ns = probs_ns > 0
   408                                                   
   409         3        903.0    301.0      0.4          if np.any(mask_ns):
   410                                                       # Construct Next States Matrix
   411         6       7111.0   1185.2      3.0              NS_states = np.column_stack((
   412         3        746.0    248.7      0.3                  Y_next[mask_ns], 
   413         3        277.0     92.3      0.1                  V_next[mask_ns], 
   414         3       6817.0   2272.3      2.8                  Hat_D_sub[mask_ns], 
   415         3       5847.0   1949.0      2.4                  Hat_H_sub[mask_ns]
   416                                                       ))
   417                                                       
   418                                                       # FAST LOOKUP via Hashing
   419         3      29756.0   9918.7     12.4              dest_idxs, found = get_state_indices(NS_states)
   420                                                       
   421         3         58.0     19.3      0.0              if len(dest_idxs) > 0:
   422         3        469.0    156.3      0.2                  rows_list.append(src_idxs[mask_ns][found])
   423         3         31.0     10.3      0.0                  cols_list.append(dest_idxs)
   424         3        578.0    192.7      0.2                  data_list.append(probs_ns[mask_ns][found])
   425                                           
   426                                                   # --- PATH B: SPAWN ---
   427         3        269.0     89.7      0.1          mask_s = (p_spawn_sub > 0)
   428         3        760.0    253.3      0.3          if np.any(mask_s) and len(C.S_h) > 0:
   429                                                       # Subset for spawn calculations
   430         3        311.0    103.7      0.1              S_Y = Y_next[mask_s]
   431         3        353.0    117.7      0.1              S_V = V_next[mask_s]
   432         3        207.0     69.0      0.1              S_src = src_idxs[mask_s]
   433         3       1314.0    438.0      0.5              S_D = Hat_D_sub[mask_s]
   434         3       1227.0    409.0      0.5              S_H = Hat_H_sub[mask_s]
   435         3       1642.0    547.3      0.7              S_k = k_spawn_indices[src_idxs][mask_s]
   436                                                       
   437                                                       # Base probability for this branch
   438         3        460.0    153.3      0.2              S_base_prob = prob_flap * p_spawn_sub[mask_s]
   439                                                       
   440                                                       # Calculate 's' distance to fill
   441                                                       # s = X - 1 - sum(d)
   442         3       2041.0    680.3      0.9              S_s_fill = np.clip((C.X - 1) - np.sum(S_D, axis=1), C.D_min, C.X - 1)
   443                                           
   444                                                       # Iterate over possible new heights (Uniform probability)
   445        12        100.0      8.3      0.0              for h_new in C.S_h:
   446                                                           # Construct new pipe arrays
   447         9        269.0     29.9      0.1                  D_new = S_D.copy()
   448         9        218.0     24.2      0.1                  H_new = S_H.copy()
   449                                                           
   450                                                           # Update the specific pipe k
   451         9        521.0     57.9      0.2                  row_indices = np.arange(len(S_Y))
   452         9       2401.0    266.8      1.0                  D_new[row_indices, S_k] = S_s_fill
   453         9       2213.0    245.9      0.9                  H_new[row_indices, S_k] = h_new
   454                                                           
   455                                                           # Construct State Matrix
   456         9       4021.0    446.8      1.7                  S_states = np.column_stack((S_Y, S_V, D_new, H_new))
   457                                                           
   458                                                           # FAST LOOKUP
   459         9      16148.0   1794.2      6.7                  dest_idxs, found = get_state_indices(S_states)
   460                                                           
   461         9        112.0     12.4      0.0                  if len(dest_idxs) > 0:
   462         9        287.0     31.9      0.1                      rows_list.append(S_src[found])
   463         9         65.0      7.2      0.0                      cols_list.append(dest_idxs)
   464                                                               # p = base_prob * (1/|Sh|)
   465         9        667.0     74.1      0.3                      data_list.append(S_base_prob[found] * prob_h_new)
   466                                           
   467                                                   # Build CSR Matrix for this input u
   468         3         33.0     11.0      0.0          if len(data_list) > 0:
   469         3        259.0     86.3      0.1              data = np.concatenate(data_list)
   470         3        207.0     69.0      0.1              rows = np.concatenate(rows_list)
   471         3        195.0     65.0      0.1              cols = np.concatenate(cols_list)
   472         3      29736.0   9912.0     12.4              P_mat = sp.csr_matrix((data, (rows, cols)), shape=(C.K, C.K))
   473                                                   else:
   474                                                       P_mat = sp.csr_matrix((C.K, C.K))
   475                                                       
   476         3         41.0     13.7      0.0          P_sparse_list.append(P_mat)
   477                                           
   478         1          4.0      4.0      0.0      return P_sparse_list

