Timer unit: 1e-07 s

Total time: 0.370687 s
Function: solution at line 31

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    31                                           def solution(C: Const) -> tuple[np.ndarray, np.ndarray]:
    32                                               # 1. Setup Phase
    33                                               # -----------------------------------------------------
    34         1         63.0     63.0      0.0      Total_start = time.perf_counter()
    35         1       1771.0   1771.0      0.0      print("Computing Transition Probabilities... (Optimized Hashing)")
    36                                               
    37         1         60.0     60.0      0.0      T_start = time.perf_counter()
    38                                               # Call the optimized function from utils.py
    39         1     254648.0 254648.0      6.9      P_list = compute_transition_probabilities_vectorized(C)
    40                                               
    41                                               # Convert to CSR immediately for fast arithmetic
    42         1        109.0    109.0      0.0      P_actions = [p.tocsr() for p in P_list]
    43                                               
    44                                               # Pre-compute stacked version for Cost calculation (P_stack @ J)
    45         1       5425.0   5425.0      0.1      P_stack = sp.vstack(P_actions).tocsr()
    46         1         33.0     33.0      0.0      T_end = time.perf_counter()
    47                                           
    48         1       1747.0   1747.0      0.0      print("Computing Stage Costs...")
    49                                               # Assuming standard fast cost computation
    50         1       2715.0   2715.0      0.1      Q = compute_expected_stage_cost_fast(C, C.K)
    51                                               
    52                                               # 2. Solver Parameters
    53                                               # -----------------------------------------------------
    54         1        203.0    203.0      0.0      K, L = C.K, C.L
    55         1         14.0     14.0      0.0      gamma = 1.0
    56         1         35.0     35.0      0.0      dtype = np.float64
    57                                               
    58                                               # Initialization
    59         1        574.0    574.0      0.0      J = np.zeros(K, dtype=dtype)
    60         1        281.0    281.0      0.0      policy = np.zeros(K, dtype=int)
    61                                               
    62                                               # Pre-allocate range for indexing
    63         1        480.0    480.0      0.0      range_k = np.arange(K, dtype=int)
    64                                               
    65                                               # Pre-build Identity matrix (CSR)
    66         1       6813.0   6813.0      0.2      I_mat = sp.eye(K, format='csr', dtype=dtype)
    67                                           
    68                                               # Tuning for GMRES speed
    69                                               # We use a loose tolerance initially and tighten it only if needed (adaptive)
    70         1         17.0     17.0      0.0      max_outer_iters = 200
    71         1         13.0     13.0      0.0      outer_tol = 1e-7
    72         1         13.0     13.0      0.0      gmres_tol_max = 1e-4
    73         1         15.0     15.0      0.0      gmres_tol_min = 1e-8
    74         1          8.0      8.0      0.0      gmres_restart = 60
    75         1          8.0      8.0      0.0      max_inner_iters = 30 # Higher inner iters = fewer restarts = faster
    76                                           
    77         1         12.0     12.0      0.0      delta_J_prev = 1.0
    78                                               
    79         1         42.0     42.0      0.0      solve_start = time.perf_counter()
    80                                           
    81                                               # 3. Policy Iteration Loop
    82                                               # -----------------------------------------------------
    83        23        261.0     11.3      0.0      for outer_iter in range(max_outer_iters):
    84        23       2482.0    107.9      0.1          J_prev = J.copy()
    85                                           
    86                                                   # --- A. Optimized Matrix Construction (Masking) ---
    87                                                   # Goal: Construct A = I - gamma * P_pi
    88                                                   # Method: P_pi = Mask_0 * P_0 + Mask_1 * P_1 ...
    89                                                   # This is much faster than slicing rows in Python.
    90                                                   
    91        23      48032.0   2088.3      1.3          P_pi_accum = sp.csr_matrix((K, K), dtype=dtype)
    92                                                   
    93        92       1001.0     10.9      0.0          for l in range(L):
    94                                                       # Boolean array where policy chooses action l
    95        69       6954.0    100.8      0.2              is_action_l = (policy == l)
    96                                                       
    97                                                       # Skip if action is not used
    98        69      14459.0    209.6      0.4              if not np.any(is_action_l):
    99         2         14.0      7.0      0.0                  continue
   100                                                           
   101                                                       # Create diagonal mask matrix
   102                                                       # casting boolean to int/float creates 0s and 1s on diagonal
   103        67     513781.0   7668.4     13.9              Mask_l = sp.diags(is_action_l.astype(dtype), format='csr')
   104                                                       
   105                                                       # Add to accumulator: Mask * P_l (Efficient C-level sparse mult)
   106        67     601149.0   8972.4     16.2              P_pi_accum += Mask_l.dot(P_actions[l])
   107                                                   
   108                                                   # A = I - gamma * P_pi
   109        23     151168.0   6572.5      4.1          A_sparse = I_mat - gamma * P_pi_accum
   110                                           
   111                                                   # --- B. Preconditioner ---
   112                                                   # Simple Jacobi/ILU approximation helps GMRES converge faster
   113                                                   # Recomputing every step is cheap enough compared to the solve
   114        23      32291.0   1404.0      0.9          M_precond = make_preconditioner(A_sparse, omega=0.8, inner_iters=3, dtype=dtype)
   115                                           
   116                                                   # --- C. Right-Hand Side ---
   117        23      16515.0    718.0      0.4          b = Q[range_k, policy].astype(dtype)
   118                                           
   119                                                   # --- D. Adaptive Tolerance ---
   120                                                   # If we are far from convergence (high delta), we don't need a precise linear solve.
   121        23        234.0     10.2      0.0          if outer_iter > 0:
   122        22        286.0     13.0      0.0              tol_k = 0.5 * delta_J_prev 
   123                                                   else:
   124         1          8.0      8.0      0.0              tol_k = gmres_tol_max
   125        23        524.0     22.8      0.0          tol_k = min(max(tol_k, gmres_tol_min), gmres_tol_max)
   126                                           
   127                                                   # --- E. Linear Solve (GMRES) ---
   128        23        125.0      5.4      0.0          try:
   129        46    1935292.0  42071.6     52.2              J_eval, info = spla.gmres(
   130        23        144.0      6.3      0.0                  A_sparse, b, x0=J, 
   131        23         94.0      4.1      0.0                  tol=tol_k, 
   132        23        129.0      5.6      0.0                  restart=gmres_restart, 
   133        23        120.0      5.2      0.0                  maxiter=max_inner_iters, 
   134        23         89.0      3.9      0.0                  M=M_precond
   135                                                       )
   136        23        336.0     14.6      0.0              if info != 0:
   137                                                           # Fallback to direct solve if GMRES fails (rare)
   138                                                           J_eval = spla.spsolve(A_sparse, b)
   139                                                   except Exception:
   140                                                       J_eval = spla.spsolve(A_sparse, b)
   141                                           
   142                                                   # --- F. Policy Improvement ---
   143                                                   # Compute Expected Future Costs for ALL actions simultaneously
   144                                                   # P_stack is (L*K, K). J is (K,). Result is (L*K,).
   145        23      23018.0   1000.8      0.6          P_J_all = P_stack.dot(J_eval)
   146                                                   
   147                                                   # Reshape to (L, K) -> Transpose to (K, L)
   148                                                   # Row k contains [Cost_Act0, Cost_Act1, ...]
   149        23        943.0     41.0      0.0          future_costs = P_J_all.reshape((L, K)).T
   150                                                   
   151        23      22724.0    988.0      0.6          Q_J = Q + gamma * future_costs
   152                                                   
   153                                                   # Greedy Update
   154        23      32954.0   1432.8      0.9          new_policy = np.argmin(Q_J, axis=1)
   155                                           
   156                                                   # --- G. Convergence Check ---
   157        23      11147.0    484.7      0.3          policy_changes = np.sum(new_policy != policy)
   158        23       7733.0    336.2      0.2          delta_J = np.max(np.abs(J_eval - J_prev))
   159                                           
   160        23        150.0      6.5      0.0          delta_J_prev = delta_J
   161        23        247.0     10.7      0.0          J = J_eval
   162        23        204.0      8.9      0.0          policy = new_policy
   163                                           
   164        23        252.0     11.0      0.0          if policy_changes == 0 and delta_J < outer_tol:
   165         1       2248.0   2248.0      0.1              print(f"Converged in {outer_iter+1} iterations.")
   166         1         12.0     12.0      0.0              break
   167                                                   
   168        22        253.0     11.5      0.0          if outer_iter == max_outer_iters - 1:
   169                                                       print("Warning: Max outer iterations reached without convergence.")
   170                                           
   171                                               # 4. Final Timing Stats
   172                                               # -----------------------------------------------------
   173         1         43.0     43.0      0.0      Total_time = time.perf_counter() - Total_start
   174         1          9.0      9.0      0.0      T_setup = T_end - T_start
   175         1         15.0     15.0      0.0      T_solve = time.perf_counter() - solve_start
   176                                               
   177         1       1862.0   1862.0      0.1      print("\n--- Timing Summary (Fully Optimized) ---")
   178         1        975.0    975.0      0.0      print(f"Transition Setup (Hashing): {T_setup:.6f}s")
   179         1        613.0    613.0      0.0      print(f"Solver Loop (Masking):      {T_solve:.6f}s")
   180         1        865.0    865.0      0.0      print(f"Total Runtime:              {Total_time:.6f}s")
   181                                           
   182         1         12.0     12.0      0.0      return J, policy

Total time: 0.0246832 s
File: C:\Users\tobyt\OneDrive\ETH OneDrive_Personal\Master\DPOC\DPOC_Exercise\utils.py
Function: compute_transition_probabilities_vectorized at line 232

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   232                                           def compute_transition_probabilities_vectorized(C):
   233                                               """
   234                                               Optimized transition probability calculation using Coordinate Hashing.
   235                                               
   236                                               Improvements:
   237                                               1. Coordinate Hashing: Maps (y, v, d, h) -> Integer Index in O(1).
   238                                                  Replaces np.searchsorted (O(N log N)).
   239                                               2. Vectorized Physics: Strictly follows PDF dynamics (Collision, Spawning, Motion).
   240                                               """
   241                                           
   242                                               # 1. Parse State Space & Setup Hashing
   243                                               # ---------------------------------------------------------
   244         1      49570.0  49570.0     20.1      S_arr = np.array(C.state_space, dtype=np.int32)
   245         1         50.0     50.0      0.0      N = S_arr.shape[0]
   246         1         15.0     15.0      0.0      num_cols = S_arr.shape[1]
   247                                           
   248                                               # Calculate ranges and strides for Perfect Hashing
   249                                               # We map every state to a unique integer: Hash = Sum( (val - min) * stride )
   250         1       4070.0   4070.0      1.6      mins = S_arr.min(axis=0)
   251         1       3616.0   3616.0      1.5      maxs = S_arr.max(axis=0)
   252         1        259.0    259.0      0.1      ranges = maxs - mins + 1
   253                                               
   254                                               # Compute strides (column-major-like logic, but order doesn't matter as long as consistent)
   255         1         61.0     61.0      0.0      strides = np.zeros(num_cols, dtype=np.int64)
   256         1          8.0      8.0      0.0      current_stride = 1
   257         7         98.0     14.0      0.0      for i in range(num_cols):
   258         6         83.0     13.8      0.0          strides[i] = current_stride
   259         6        121.0     20.2      0.0          current_stride *= ranges[i]
   260                                           
   261                                               # Total size of the dense lookup table
   262         1          8.0      8.0      0.0      table_size = current_stride
   263                                               
   264                                               # Safety Check: If table is > 100MB (approx 25M entries), warn or fallback.
   265                                               # For Flappy Bird, table_size is usually < 5,000,000 (20MB), which is fine.
   266                                               
   267                                               # Create the lookup table
   268                                               # lookup_table[hash] = index_in_state_space
   269         1       3999.0   3999.0      1.6      lookup_table = np.full(table_size, -1, dtype=np.int32)
   270                                               
   271                                               # Compute hashes for all existing valid states
   272                                               # Formula: sum((S_arr[:, i] - mins[i]) * strides[i])
   273         1       4883.0   4883.0      2.0      state_hashes = np.dot((S_arr - mins), strides)
   274         1        581.0    581.0      0.2      lookup_table[state_hashes] = np.arange(N, dtype=np.int32)
   275                                           
   276                                               # Helper for O(1) Lookup
   277         1         46.0     46.0      0.0      def get_state_indices(next_states):
   278                                                   # 1. Check bounds (vectorized)
   279                                                   # Any state component outside [min, max] is invalid
   280                                                   valid_bounds = np.all((next_states >= mins) & (next_states <= maxs), axis=1)
   281                                                   
   282                                                   indices = np.full(next_states.shape[0], -1, dtype=np.int32)
   283                                                   
   284                                                   if np.any(valid_bounds):
   285                                                       # 2. Compute Hashes
   286                                                       # Subset only valid bounds to avoid overflow/segfaults on hash calculation
   287                                                       valid_states = next_states[valid_bounds]
   288                                                       hashes = np.dot((valid_states - mins), strides)
   289                                                       
   290                                                       # 3. Lookup
   291                                                       # Since we checked bounds, hashes are guaranteed < table_size
   292                                                       found_indices = lookup_table[hashes]
   293                                                       indices[valid_bounds] = found_indices
   294                                                       
   295                                                   # Return indices and a boolean mask of which ones were found
   296                                                   mask_found = (indices != -1)
   297                                                   return indices[mask_found], mask_found
   298                                           
   299                                               # 2. Pre-process State Columns
   300                                               # ---------------------------------------------------------
   301         1         33.0     33.0      0.0      Y = S_arr[:, 0]
   302         1         21.0     21.0      0.0      V = S_arr[:, 1]
   303         1        118.0    118.0      0.0      D = S_arr[:, 2 : 2 + C.M]
   304         1         63.0     63.0      0.0      H = S_arr[:, 2 + C.M : 2 + 2 * C.M]
   305                                           
   306                                               # Collision Logic (PDF: "transition to a cost-free termination state")
   307                                               # We treat these as absorbing (rows of 0 in P), effectively removing them from the game flow.
   308         1         30.0     30.0      0.0      if C.M > 0:
   309         1         13.0     13.0      0.0          gap_tol = (C.G - 1) // 2
   310                                                   # Collision if inside pipe horizontally (D=0) AND outside gap vertically
   311         1       2741.0   2741.0      1.1          is_collided = (D[:, 0] == 0) & (np.abs(Y - H[:, 0]) > gap_tol)
   312                                               else:
   313                                                   is_collided = np.zeros(N, dtype=bool)
   314                                           
   315                                               # 3. Deterministic Pipe Dynamics (Pre-calculated)
   316                                               # ---------------------------------------------------------
   317         1        852.0    852.0      0.3      Hat_D = D.copy()
   318         1       2519.0   2519.0      1.0      Hat_H = H.copy()
   319                                           
   320         1        130.0    130.0      0.1      if C.M > 0:
   321                                                   # Mask: Pipes that are currently at x=0 (Passing/Recycling)
   322         1        339.0    339.0      0.1          mask_passing = (D[:, 0] == 0)
   323                                                   
   324                                                   # Shift pipes left
   325         1         63.0     63.0      0.0          if C.M > 1:
   326         1       1598.0   1598.0      0.6              Hat_D[mask_passing, :-1] = D[mask_passing, 1:]
   327         1       1732.0   1732.0      0.7              Hat_H[mask_passing, :-1] = H[mask_passing, 1:]
   328                                                   
   329                                                   # Reset last pipe (will be filled by spawn logic if applicable)
   330         1        765.0    765.0      0.3          Hat_D[mask_passing, C.M-1] = 0
   331         1         51.0     51.0      0.0          if len(C.S_h) > 0:
   332         1        707.0    707.0      0.3              Hat_H[mask_passing, C.M-1] = C.S_h[0] # Default height
   333                                           
   334                                                   # Decrement horizontal distance (Drift)
   335                                                   # Only decrement if not just reset (checked by > 0)
   336         1        254.0    254.0      0.1          mask_dec = (Hat_D[:, 0] > 0)
   337         1       1592.0   1592.0      0.6          Hat_D[mask_dec, 0] -= 1
   338                                           
   339                                               # Spawn Probability Logic (Linear Ramp)
   340         1       2030.0   2030.0      0.8      sum_hat_D = np.sum(Hat_D, axis=1)
   341         1        112.0    112.0      0.0      s_values = (C.X - 1) - sum_hat_D # Free space
   342                                               
   343                                               # p = (s - (Dmin-1)) / (X - Dmin)
   344         1         96.0     96.0      0.0      numerator = s_values - (C.D_min - 1)
   345         1         28.0     28.0      0.0      denominator = float(C.X - C.D_min)
   346         1        966.0    966.0      0.4      p_spawn_vec = np.clip(numerator / denominator, 0.0, 1.0)
   347                                               
   348                                               # Identify which pipe index 'k' to spawn into (first available slot)
   349         1        278.0    278.0      0.1      k_spawn_indices = np.full(N, C.M - 1, dtype=int)
   350         1         34.0     34.0      0.0      if C.M > 1:
   351                                                   # Find first column where D=0
   352         1        189.0    189.0      0.1          is_zero = (Hat_D[:, 1:] == 0)
   353         1        485.0    485.0      0.2          any_zero = np.any(is_zero, axis=1)
   354         1       1015.0   1015.0      0.4          first_zero = np.argmax(is_zero, axis=1)
   355         1        391.0    391.0      0.2          k_spawn_indices[any_zero] = first_zero[any_zero] + 1
   356                                           
   357                                               # 4. Input Loop & Matrix Construction
   358                                               # ---------------------------------------------------------
   359         1         32.0     32.0      0.0      prob_h_new = 1.0 / len(C.S_h) if len(C.S_h) > 0 else 0.0
   360         1        106.0    106.0      0.0      U_array = np.array(C.input_space)
   361                                               
   362         1          9.0      9.0      0.0      P_sparse_list = []
   363                                           
   364         4        106.0     26.5      0.0      for u in U_array:
   365                                                   # Initialize Coordinate Lists for Sparse Matrix
   366         3         49.0     16.3      0.0          rows_list = []
   367         3         35.0     11.7      0.0          cols_list = []
   368         3         35.0     11.7      0.0          data_list = []
   369                                                   
   370                                                   # Resolve Flap/Wind randomness
   371         3         41.0     13.7      0.0          if u == C.U_strong:
   372         1         38.0     38.0      0.0              W_flap = np.arange(-C.V_dev, C.V_dev + 1)
   373                                                   else:
   374         2         55.0     27.5      0.0              W_flap = np.array([0])
   375                                                   
   376         3         43.0     14.3      0.0          prob_flap = 1.0 / len(W_flap)
   377         3         26.0      8.7      0.0          n_w = len(W_flap)
   378                                           
   379                                                   # Vectorized Next State Calculation
   380                                                   # v_{k+1} = v_k + u + w - g
   381                                                   # Broadcast: (N, 1) + scalar + (1, n_w) -> (N, n_w)
   382         3       2499.0    833.0      1.0          V_next_matrix = V[:, None] + u + W_flap[None, :] - C.g
   383         3        812.0    270.7      0.3          V_next_flat = np.clip(V_next_matrix, -C.V_max, C.V_max).flatten()
   384                                                   
   385                                                   # y_{k+1} = y_k + v_k (Note: Uses CURRENT v_k)
   386         3       2566.0    855.3      1.0          Y_repeated = np.repeat(Y, n_w)
   387         3       2518.0    839.3      1.0          V_curr_repeated = np.repeat(V, n_w)
   388         3       1612.0    537.3      0.7          Y_next_flat = np.clip(Y_repeated + V_curr_repeated, 0, C.Y - 1).astype(np.int32)
   389                                                   
   390                                                   # Filter Collided Sources (They don't transition)
   391         3       2745.0    915.0      1.1          source_idxs_base = np.repeat(np.arange(N), n_w)
   392         3       2614.0    871.3      1.1          valid_src_mask = ~np.repeat(is_collided, n_w)
   393                                                   
   394                                                   # Apply mask
   395         3        622.0    207.3      0.3          V_next = V_next_flat[valid_src_mask]
   396         3        299.0     99.7      0.1          Y_next = Y_next_flat[valid_src_mask]
   397         3        598.0    199.3      0.2          src_idxs = source_idxs_base[valid_src_mask]
   398                                                   
   399                                                   # Get pipe state for these sources
   400         3       4952.0   1650.7      2.0          Hat_D_sub = Hat_D[src_idxs]
   401         3       4574.0   1524.7      1.9          Hat_H_sub = Hat_H[src_idxs]
   402         3       1562.0    520.7      0.6          p_spawn_sub = p_spawn_vec[src_idxs]
   403                                                   
   404                                                   # --- PATH A: NO SPAWN ---
   405                                                   # Prob = prob_flap * (1 - p_spawn)
   406         3       1022.0    340.7      0.4          probs_ns = prob_flap * (1.0 - p_spawn_sub)
   407         3        305.0    101.7      0.1          mask_ns = probs_ns > 0
   408                                                   
   409         3        745.0    248.3      0.3          if np.any(mask_ns):
   410                                                       # Construct Next States Matrix
   411         6       6717.0   1119.5      2.7              NS_states = np.column_stack((
   412         3        340.0    113.3      0.1                  Y_next[mask_ns], 
   413         3        228.0     76.0      0.1                  V_next[mask_ns], 
   414         3       6023.0   2007.7      2.4                  Hat_D_sub[mask_ns], 
   415         3       6241.0   2080.3      2.5                  Hat_H_sub[mask_ns]
   416                                                       ))
   417                                                       
   418                                                       # FAST LOOKUP via Hashing
   419         3      31140.0  10380.0     12.6              dest_idxs, found = get_state_indices(NS_states)
   420                                                       
   421         3         57.0     19.0      0.0              if len(dest_idxs) > 0:
   422         3        723.0    241.0      0.3                  rows_list.append(src_idxs[mask_ns][found])
   423         3         27.0      9.0      0.0                  cols_list.append(dest_idxs)
   424         3        960.0    320.0      0.4                  data_list.append(probs_ns[mask_ns][found])
   425                                           
   426                                                   # --- PATH B: SPAWN ---
   427         3        390.0    130.0      0.2          mask_s = (p_spawn_sub > 0)
   428         3        656.0    218.7      0.3          if np.any(mask_s) and len(C.S_h) > 0:
   429                                                       # Subset for spawn calculations
   430         3        257.0     85.7      0.1              S_Y = Y_next[mask_s]
   431         3        263.0     87.7      0.1              S_V = V_next[mask_s]
   432         3        254.0     84.7      0.1              S_src = src_idxs[mask_s]
   433         3       1534.0    511.3      0.6              S_D = Hat_D_sub[mask_s]
   434         3       1439.0    479.7      0.6              S_H = Hat_H_sub[mask_s]
   435         3       1167.0    389.0      0.5              S_k = k_spawn_indices[src_idxs][mask_s]
   436                                                       
   437                                                       # Base probability for this branch
   438         3        477.0    159.0      0.2              S_base_prob = prob_flap * p_spawn_sub[mask_s]
   439                                                       
   440                                                       # Calculate 's' distance to fill
   441                                                       # s = X - 1 - sum(d)
   442         3       1938.0    646.0      0.8              S_s_fill = np.clip((C.X - 1) - np.sum(S_D, axis=1), C.D_min, C.X - 1)
   443                                           
   444                                                       # Iterate over possible new heights (Uniform probability)
   445        12        112.0      9.3      0.0              for h_new in C.S_h:
   446                                                           # Construct new pipe arrays
   447         9        270.0     30.0      0.1                  D_new = S_D.copy()
   448         9        318.0     35.3      0.1                  H_new = S_H.copy()
   449                                                           
   450                                                           # Update the specific pipe k
   451         9        467.0     51.9      0.2                  row_indices = np.arange(len(S_Y))
   452         9       2351.0    261.2      1.0                  D_new[row_indices, S_k] = S_s_fill
   453         9       2101.0    233.4      0.9                  H_new[row_indices, S_k] = h_new
   454                                                           
   455                                                           # Construct State Matrix
   456         9       5391.0    599.0      2.2                  S_states = np.column_stack((S_Y, S_V, D_new, H_new))
   457                                                           
   458                                                           # FAST LOOKUP
   459         9      23920.0   2657.8      9.7                  dest_idxs, found = get_state_indices(S_states)
   460                                                           
   461         9        128.0     14.2      0.1                  if len(dest_idxs) > 0:
   462         9        335.0     37.2      0.1                      rows_list.append(S_src[found])
   463         9         67.0      7.4      0.0                      cols_list.append(dest_idxs)
   464                                                               # p = base_prob * (1/|Sh|)
   465         9        879.0     97.7      0.4                      data_list.append(S_base_prob[found] * prob_h_new)
   466                                           
   467                                                   # Build CSR Matrix for this input u
   468         3         34.0     11.3      0.0          if len(data_list) > 0:
   469         3        363.0    121.0      0.1              data = np.concatenate(data_list)
   470         3        535.0    178.3      0.2              rows = np.concatenate(rows_list)
   471         3        611.0    203.7      0.2              cols = np.concatenate(cols_list)
   472         3      30745.0  10248.3     12.5              P_mat = sp.csr_matrix((data, (rows, cols)), shape=(C.K, C.K))
   473                                                   else:
   474                                                       P_mat = sp.csr_matrix((C.K, C.K))
   475                                                       
   476         3         37.0     12.3      0.0          P_sparse_list.append(P_mat)
   477                                           
   478         1          4.0      4.0      0.0      return P_sparse_list

