Timer unit: 1e-09 s

Total time: 0.256955 s
Average time: 0.256955 s
File: /home/gblum/dev/DPOC_Exercise/Solver.py
Function: solution at line 31

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    31                                           def solution(C: Const) -> tuple[np.ndarray, np.ndarray]: 
    32         1       3533.0   3533.0      0.0      Total_start = time.perf_counter()
    33                                           
    34         1      19614.0  19614.0      0.0      print("Computing Transition Probabilities... (fast)")
    35         1       1205.0   1205.0      0.0      T_start_time = time.perf_counter()
    36         1   27282171.0 2.73e+07     10.6      P_list = compute_transition_probabilities_vectorized(C)#compute_transition_probabilities_fast(C)
    37                                               
    38                                               # --- OPTIMIZATION: Pre-Stack P Matrices ---
    39         1     652842.0 652842.0      0.3      P_stack = sp.vstack(P_list).tocsr()
    40                                               
    41         1     151830.0 151830.0      0.1      del P_list 
    42                                               
    43         1       5258.0   5258.0      0.0      T_end_time = time.perf_counter()
    44                                           
    45         1      52321.0  52321.0      0.0      print("Computing Stage Costs...")
    46         1       1368.0   1368.0      0.0      SC_start_time = time.perf_counter()
    47         1     242275.0 242275.0      0.1      Q = compute_expected_stage_cost(C)
    48         1       1647.0   1647.0      0.0      SC_end_time = time.perf_counter()
    49                                           
    50                                               # --- iGMRES & Solver Parameters ---
    51         1       8486.0   8486.0      0.0      K, L = C.K, C.L
    52         1        766.0    766.0      0.0      gamma = 1.0
    53         1       2605.0   2605.0      0.0      dtype = np.float64
    54                                           
    55         1       8721.0   8721.0      0.0      J = np.zeros(K, dtype=dtype)
    56         1       4487.0   4487.0      0.0      policy = np.zeros(K, dtype=int)  
    57                                           
    58                                               # Tolerances
    59         1        484.0    484.0      0.0      gmres_tol_max = 1e-5
    60         1        689.0    689.0      0.0      gmres_tol_min = 1e-9
    61         1        675.0    675.0      0.0      eta = 0.5
    62         1        537.0    537.0      0.0      outer_tol = 1e-7
    63                                           
    64                                               # Iteration limits
    65         1        497.0    497.0      0.0      max_outer_iters = 200
    66         1        703.0    703.0      0.0      gmres_restart = 60
    67         1        712.0    712.0      0.0      max_inner_iters = 15
    68                                               
    69         1        764.0    764.0      0.0      delta_J_prev = 1.0
    70         1      19680.0  19680.0      0.0      range_k = np.arange(K, dtype=int) # Pre-compute for slicing
    71                                           
    72         1        730.0    730.0      0.0      start_time = time.perf_counter()
    73                                           
    74                                               # Begin iterations
    75        26      24333.0    935.9      0.0      for outer_iter in range(max_outer_iters):
    76        26     201281.0   7741.6      0.1          J_prev = J.copy()
    77                                           
    78                                                   # --- 1. Build A (Optimized) ---
    79        26   38433462.0 1.48e+06     15.0          A_sparse = build_A(K, P_stack, policy, range_k, gamma, dtype)
    80                                           
    81                                                   # --- 2. Preconditioner ---
    82        26    4590320.0 176550.8      1.8          M = make_preconditioner(A_sparse, omega=0.8, inner_iters=3, dtype=dtype)
    83                                           
    84                                                   # Right-hand side
    85        26    2418167.0  93006.4      0.9          b = Q[range_k, policy].astype(dtype)
    86                                           
    87                                                   # Adaptive GMRES Tolerance
    88                                                   # If delta_J is large, we don't need a perfect linear solve yet.
    89        26      19360.0    744.6      0.0          if outer_iter > 0:
    90        25      40126.0   1605.0      0.0              tol_k = eta * delta_J_prev
    91                                                   else:
    92         1        659.0    659.0      0.0              tol_k = gmres_tol_max
    93                                                       
    94        26      73662.0   2833.2      0.0          tol_k = min(max(tol_k, gmres_tol_min), gmres_tol_max)
    95                                           
    96                                                   # --- 3. Solve Linear System ---
    97        26      10957.0    421.4      0.0          try:
    98        52  169429481.0 3.26e+06     65.9              J_eval, info = spla.gmres(
    99        26      10504.0    404.0      0.0                  A_sparse,
   100        26       9091.0    349.7      0.0                  b,
   101        26      10563.0    406.3      0.0                  x0=J,
   102        26       8400.0    323.1      0.0                  tol=tol_k,
   103        26       9452.0    363.5      0.0                  restart=gmres_restart,
   104        26      10275.0    395.2      0.0                  maxiter=max_inner_iters,
   105        26       8623.0    331.7      0.0                  M=M
   106                                                       )
   107        26      28968.0   1114.2      0.0              if info != 0:
   108                                                           J_eval = spla.spsolve(A_sparse, b)
   109                                                   except Exception:
   110                                                       J_eval = spla.spsolve(A_sparse, b)
   111                                           
   112                                                   # --- 4. Policy Improvement (Optimized) ---
   113        26    3321590.0 127753.5      1.3          P_J_all = P_stack.dot(J_eval)
   114                                                   
   115        26     107363.0   4129.3      0.0          expected_future_costs = P_J_all.reshape((L, K)).T
   116                                                   
   117                                                   # Bellman update
   118        26    3476025.0 133693.3      1.4          Q_J = Q + gamma * expected_future_costs
   119                                           
   120                                                   # Greedy improvement
   121        26    3256325.0 125243.3      1.3          new_policy = np.argmin(Q_J, axis=1)
   122                                           
   123                                                   # Stats
   124        26    1561839.0  60070.7      0.6          policy_changes = np.sum(new_policy != policy)
   125        26    1233704.0  47450.2      0.5          delta_J = np.max(np.abs(J_eval - J_prev))
   126                                           
   127        26      16099.0    619.2      0.0          delta_J_prev = delta_J
   128        26      27621.0   1062.3      0.0          J = J_eval
   129        26      22160.0    852.3      0.0          policy = new_policy
   130                                           
   131        26      55057.0   2117.6      0.0          if policy_changes == 0 and delta_J < outer_tol:
   132         1      23149.0  23149.0      0.0              print(f"Converged in {outer_iter+1} iterations.")
   133         1        510.0    510.0      0.0              break
   134                                               else:
   135                                                   print("Warning: Max outer iterations reached without convergence.")
   136                                           
   137         1       2007.0   2007.0      0.0      end_time = time.perf_counter()
   138                                           
   139         1       1429.0   1429.0      0.0      T_TP = T_end_time - T_start_time
   140         1        667.0    667.0      0.0      T_SC = SC_end_time - SC_start_time
   141         1        487.0    487.0      0.0      T_J = end_time - start_time
   142         1       1067.0   1067.0      0.0      Total_time = time.perf_counter() - Total_start
   143                                           
   144         1      11492.0  11492.0      0.0      print("\n--- Timing Summary (Optimized with Slicing) ---")
   145         1      10729.0  10729.0      0.0      print(f"Transition Probabilities: {T_TP:.6f}s")
   146         1       7382.0   7382.0      0.0      print(f"Stage Costs:              {T_SC:.6f}s")
   147         1       6118.0   6118.0      0.0      print(f"Policy Iteration:         {T_J:.6f}s")
   148         1       9624.0   9624.0      0.0      print(f"Total Runtime:            {Total_time:.6f}s")
   149                                           
   150         1        580.0    580.0      0.0      return J, policy

Total time: 0.0268315 s
Average time: 0.0268315 s
File: /home/gblum/dev/DPOC_Exercise/utils.py
Function: compute_transition_probabilities_vectorized at line 245

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   245                                           def compute_transition_probabilities_vectorized(C):
   246                                               """
   247                                               Fully vectorized calculation of transition probabilities.
   248                                               Strictly adheres to PE_instructions.pdf.
   249                                           
   250                                               Corrections Implemented:
   251                                               1. Vertical Motion: y_{k+1} = y_k + v_k (Uses CURRENT velocity, not next).
   252                                               2. Pipe Logic: Shifts happen first, decrement checks NEW state.
   253                                               3. Spawn Probability: Exact linear ramp formula from PDF.
   254                                               4. m_min Logic: Defaults to M-1 (last pipe) if buffer is full.
   255                                               """
   256                                           
   257                                               # 1. Convert State Space to Matrix
   258                                               # ---------------------------------------------------------
   259         1    4179079.0 4.18e+06     15.6      S_arr = np.array(C.state_space, dtype=np.int32)
   260         1       4042.0   4042.0      0.0      N = S_arr.shape[0]
   261                                           
   262                                               # Columns: Y, V, D[0]...D[M-1], H[0]...H[M-1]
   263         1       3502.0   3502.0      0.0      Y = S_arr[:, 0]
   264         1        987.0    987.0      0.0      V = S_arr[:, 1]
   265         1      11979.0  11979.0      0.0      D = S_arr[:, 2 : 2 + C.M]
   266         1       2854.0   2854.0      0.0      H = S_arr[:, 2 + C.M : 2 + 2 * C.M]
   267                                           
   268                                               # 2. Pre-process State Lookup (SearchSorted Trick)
   269                                               # ------------------------------------------------------
   270         1      25083.0  25083.0      0.1      dtype_view = np.dtype((np.void, S_arr.dtype.itemsize * S_arr.shape[1]))
   271         1       8415.0   8415.0      0.0      S_void = np.ascontiguousarray(S_arr).view(dtype_view).ravel()
   272         1     804908.0 804908.0      3.0      sort_order = np.argsort(S_void)
   273         1      41861.0  41861.0      0.2      S_void_sorted = S_void[sort_order]
   274                                           
   275         1       1933.0   1933.0      0.0      def lookup_state_indices(next_states_matrix):
   276                                                   next_void = np.ascontiguousarray(next_states_matrix.astype(np.int32)).view(dtype_view).ravel()
   277                                                   search_indices = np.searchsorted(S_void_sorted, next_void)
   278                                                   search_indices = np.clip(search_indices, 0, N - 1)
   279                                                   found_void = S_void_sorted[search_indices]
   280                                                   valid_mask = (found_void == next_void)
   281                                                   return sort_order[search_indices], valid_mask
   282                                           
   283                                               # 3. Deterministic Pipe Dynamics (Per PDF "Dynamics" section)
   284                                               # -----------------------------------------------------------
   285                                           
   286                                               # A. Collision check
   287                                               # "On collision... transition to a cost-free termination state"
   288                                               # We identify these source states and ensure they generate NO transitions in P
   289                                               # (effectively making them absorbing or exiting the set).
   290         1       3892.0   3892.0      0.0      if C.M > 0:
   291         1       1195.0   1195.0      0.0          gap_tol = (C.G - 1) // 2
   292         1     104226.0 104226.0      0.4          is_collided = (D[:, 0] == 0) & (np.abs(Y - H[:, 0]) > gap_tol)
   293                                               else:
   294                                                   is_collided = np.zeros(N, dtype=bool)
   295                                           
   296         1      52402.0  52402.0      0.2      Hat_D = D.copy()
   297         1      47554.0  47554.0      0.2      Hat_H = H.copy()
   298                                           
   299         1       2061.0   2061.0      0.0      if C.M > 0:
   300                                                   # B. Intermediate Quantities
   301                                                   # Case 1: Passing (d[1]=0, no collision). Logic: Shift indices left.
   302         1      10959.0  10959.0      0.0          mask_passing = (D[:, 0] == 0)
   303                                           
   304         1       1867.0   1867.0      0.0          if C.M > 1:
   305                                                       # Shift indices 2..M to 1..M-1 (Python indices 1..M-1 to 0..M-2)
   306         1      73709.0  73709.0      0.3              Hat_D[mask_passing, :-1] = D[mask_passing, 1:]
   307         1      59582.0  59582.0      0.2              Hat_H[mask_passing, :-1] = H[mask_passing, 1:]
   308                                           
   309                                                   # Set last element to 0 / default height
   310         1      47556.0  47556.0      0.2          Hat_D[mask_passing, C.M-1] = 0
   311         1       2464.0   2464.0      0.0          if len(C.S_h) > 0:
   312         1      47758.0  47758.0      0.2              Hat_H[mask_passing, C.M-1] = C.S_h[0]
   313                                           
   314                                                   # C. Drift Decrement
   315                                                   # For "Normal Drift" (d[1] > 0), hat_d = d - 1.
   316                                                   # For "Passing", hat_d[1] = d[2] - 1.
   317                                                   # Since we already shifted d[2] into position 0 for passing states,
   318                                                   # we simply decrement Hat_D[0] wherever it is > 0.
   319         1      18369.0  18369.0      0.1          mask_dec = (Hat_D[:, 0] > 0)
   320         1     145216.0 145216.0      0.5          Hat_D[mask_dec, 0] -= 1
   321                                           
   322                                               # 4. Spawn Parameter Calculation
   323                                               # -----------------------------------------------
   324         1     203561.0 203561.0      0.8      sum_hat_D = np.sum(Hat_D, axis=1)
   325         1      24452.0  24452.0      0.1      s_values = (C.X - 1) - sum_hat_D
   326                                           
   327                                               # PDF Formula for p_spawn(s) implemented vectorized
   328                                               # s <= Dmin - 1: 0
   329                                               # Dmin <= s <= X - 1: linear ramp
   330                                               # s >= X: 1
   331         1       8663.0   8663.0      0.0      numerator = s_values - (C.D_min - 1)
   332         1       2048.0   2048.0      0.0      denominator = float(C.X - C.D_min)
   333         1      23309.0  23309.0      0.1      p_linear = numerator / denominator
   334         1      33124.0  33124.0      0.1      p_spawn_vec = np.clip(p_linear, 0.0, 1.0)
   335                                           
   336                                               # Find m_min: "smallest index with no assigned obstacle"
   337                                               # Python indices 1..M-1. If none, default to M-1.
   338         1      24454.0  24454.0      0.1      k_spawn_indices = np.full(N, C.M - 1, dtype=int)
   339                                           
   340         1       1840.0   1840.0      0.0      if C.M > 1:
   341         1       2251.0   2251.0      0.0          search_view = Hat_D[:, 1:]
   342         1      14900.0  14900.0      0.1          is_zero_view = (search_view == 0)
   343         1      81977.0  81977.0      0.3          first_zero_rel = np.argmax(is_zero_view, axis=1)
   344         1      28406.0  28406.0      0.1          any_zero_found = np.any(is_zero_view, axis=1)
   345         1      61896.0  61896.0      0.2          k_spawn_indices[any_zero_found] = first_zero_rel[any_zero_found] + 1
   346                                           
   347                                               # 5. Iterate Inputs & Build Matrix
   348                                               # --------------------------------
   349         1       2834.0   2834.0      0.0      prob_h_new = 1.0 / len(C.S_h) if len(C.S_h) > 0 else 0.0
   350         1       8551.0   8551.0      0.0      U_array = np.array(C.input_space)
   351                                           
   352         1       8183.0   8183.0      0.0      P_data = [[] for _ in range(C.L)]
   353         1       4163.0   4163.0      0.0      P_rows = [[] for _ in range(C.L)]
   354         1       3383.0   3383.0      0.0      P_cols = [[] for _ in range(C.L)]
   355                                           
   356         4      18676.0   4669.0      0.1      for l_idx, u in enumerate(U_array):
   357                                                   # Probabilistic Velocities
   358         3       6893.0   2297.7      0.0          if u == C.U_strong:
   359         1       3525.0   3525.0      0.0              W_flap = np.arange(-C.V_dev, C.V_dev + 1)
   360                                                   else:
   361         2      11662.0   5831.0      0.0              W_flap = np.array([0])
   362         3       6167.0   2055.7      0.0          prob_flap = 1.0 / len(W_flap)
   363         3       2280.0    760.0      0.0          n_w = len(W_flap)
   364                                           
   365                                                   # Broadcast V + u + W (Calculates v_{k+1})
   366         3     612193.0 204064.3      2.3          V_next_matrix = V[:, None] + u + W_flap[None, :] - C.g
   367         3     279141.0  93047.0      1.0          V_next_flat = np.clip(V_next_matrix, -C.V_max, C.V_max).flatten()
   368                                           
   369                                                   # Calculate y_{k+1} based on CURRENT velocity v_k (PDF Page 5 formula)
   370                                                   # y_{k+1} = min(max(y_k + v_k, 0), Y-1)
   371                                                   # We repeat Y and V (current) to match the shape of the expanded arrays
   372         3     223725.0  74575.0      0.8          Y_repeated = np.repeat(Y, n_w)
   373         3     134914.0  44971.3      0.5          V_current_repeated = np.repeat(V, n_w)
   374         3     246569.0  82189.7      0.9          Y_next_flat = np.clip(Y_repeated + V_current_repeated, 0, C.Y - 1).astype(np.int32)
   375                                           
   376                                                   # Source filtering (Collided states are dead ends)
   377         3     246866.0  82288.7      0.9          source_idxs = np.repeat(np.arange(N), n_w)
   378         3     109764.0  36588.0      0.4          valid_src = ~np.repeat(is_collided, n_w)
   379                                           
   380         3     114418.0  38139.3      0.4          V_next = V_next_flat[valid_src]
   381         3      55125.0  18375.0      0.2          Y_next = Y_next_flat[valid_src]
   382         3     142779.0  47593.0      0.5          source_idxs = source_idxs[valid_src]
   383                                           
   384                                                   # Get pre-computed pipe params for valid rows
   385         3     448702.0 149567.3      1.7          Hat_D_sub = Hat_D[source_idxs]
   386         3     444748.0 148249.3      1.7          Hat_H_sub = Hat_H[source_idxs]
   387         3     137382.0  45794.0      0.5          p_spawn_sub = p_spawn_vec[source_idxs]
   388         3     196899.0  65633.0      0.7          k_spawn_sub = k_spawn_indices[source_idxs]
   389                                           
   390                                                   # --- Path 1: No Spawn ---
   391         3     202112.0  67370.7      0.8          probs_ns = prob_flap * (1.0 - p_spawn_sub)
   392         3      55740.0  18580.0      0.2          mask_ns = probs_ns > 0
   393                                           
   394         3     197716.0  65905.3      0.7          if np.any(mask_ns):
   395         3    2303412.0 767804.0      8.6              NS_states = np.column_stack((Y_next[mask_ns], V_next[mask_ns], Hat_D_sub[mask_ns], Hat_H_sub[mask_ns]))
   396         3    5545083.0 1.85e+06     20.7              dest_idx, valid = lookup_state_indices(NS_states)
   397                                           
   398         3       5950.0   1983.3      0.0              keep = valid
   399         3     202124.0  67374.7      0.8              P_rows[l_idx].append(source_idxs[mask_ns][keep])
   400         3      51478.0  17159.3      0.2              P_cols[l_idx].append(dest_idx[keep])
   401         3     158749.0  52916.3      0.6              P_data[l_idx].append(probs_ns[mask_ns][keep])
   402                                           
   403                                                   # --- Path 2: Spawn ---
   404         3     123191.0  41063.7      0.5          mask_s = (p_spawn_sub > 0)
   405                                           
   406         3     203896.0  67965.3      0.8          if np.any(mask_s) and len(C.S_h) > 0:
   407         3      57926.0  19308.7      0.2              S_Y = Y_next[mask_s]
   408         3      73621.0  24540.3      0.3              S_V = V_next[mask_s]
   409         3     269538.0  89846.0      1.0              S_D = Hat_D_sub[mask_s]
   410         3     162586.0  54195.3      0.6              S_H = Hat_H_sub[mask_s]
   411         3      54335.0  18111.7      0.2              S_k = k_spawn_sub[mask_s]
   412         3      95161.0  31720.3      0.4              S_base_prob = prob_flap * p_spawn_sub[mask_s]
   413                                           
   414                                                       # Calculate s to fill (re-computed for flattened subset)
   415         3     155604.0  51868.0      0.6              S_sum_d = np.sum(S_D, axis=1)
   416         3      86049.0  28683.0      0.3              s_fill = np.clip((C.X - 1) - S_sum_d, C.D_min, C.X - 1)
   417                                           
   418                                                       # Iterate over all possible new heights (uniform prob)
   419        12      14428.0   1202.3      0.1              for h_new in C.S_h:
   420         9      68352.0   7594.7      0.3                  D_new = S_D.copy()
   421         9      22927.0   2547.4      0.1                  H_new = S_H.copy()
   422         9      55996.0   6221.8      0.2                  rows = np.arange(len(S_Y))
   423                                           
   424                                                           # Assign new pipe to the identified slot
   425         9     137400.0  15266.7      0.5                  D_new[rows, S_k] = s_fill
   426         9      88535.0   9837.2      0.3                  H_new[rows, S_k] = h_new
   427                                           
   428         9     567150.0  63016.7      2.1                  S_states = np.column_stack((S_Y, S_V, D_new, H_new))
   429         9    3035379.0 337264.3     11.3                  dest_idx, valid = lookup_state_indices(S_states)
   430                                           
   431         9      13796.0   1532.9      0.1                  keep = valid
   432         9     212073.0  23563.7      0.8                  P_rows[l_idx].append(source_idxs[mask_s][keep])
   433         9      24894.0   2766.0      0.1                  P_cols[l_idx].append(dest_idx[keep])
   434         9     109913.0  12212.6      0.4                  P_data[l_idx].append(S_base_prob[keep] * prob_h_new)
   435                                           
   436                                               # 6. Construct Sparse Matrices
   437         1        362.0    362.0      0.0      P_sparse = []
   438         4       9953.0   2488.2      0.0      for l in range(C.L):
   439         3       3049.0   1016.3      0.0          if len(P_data[l]) > 0:
   440         3     130765.0  43588.3      0.5              data = np.concatenate(P_data[l])
   441         3     129426.0  43142.0      0.5              rows = np.concatenate(P_rows[l])
   442         3      93260.0  31086.7      0.3              cols = np.concatenate(P_cols[l])
   443         3    2421731.0 807243.7      9.0              P_l = sp.csr_matrix((data, (rows, cols)), shape=(C.K, C.K))
   444         3       3562.0   1187.3      0.0              P_sparse.append(P_l)
   445                                                   else:
   446                                                       P_sparse.append(sp.csr_matrix((C.K, C.K)))
   447                                           
   448         1        405.0    405.0      0.0      return P_sparse

