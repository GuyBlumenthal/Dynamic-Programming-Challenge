Timer unit: 1e-07 s

Total time: 0.252321 s
File: C:\Users\tobyt\OneDrive\ETH OneDrive_Personal\Master\DPOC\DPOC_Exercise\Solver.py
Function: solution at line 31

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    31                                           def solution(C: Const) -> tuple[np.ndarray, np.ndarray]:
    32         1        120.0    120.0      0.0      Total_start = time.perf_counter()
    33                                           
    34         1       9029.0   9029.0      0.4      print("Computing Transition Probabilities... (fast)")
    35         1         33.0     33.0      0.0      T_start_time = time.perf_counter()
    36         1     250974.0 250974.0      9.9      P_list = compute_transition_probabilities_vectorized(C)#compute_transition_probabilities_fast(C)
    37                                           
    38                                               # --- OPTIMIZATION: Pre-Stack P Matrices ---
    39         1       6621.0   6621.0      0.3      P_stack = sp.vstack(P_list).tocsr()
    40                                           
    41         1       1088.0   1088.0      0.0      del P_list
    42                                           
    43         1         44.0     44.0      0.0      T_end_time = time.perf_counter()
    44         1         73.0     73.0      0.0      K = C.K
    45         1       2873.0   2873.0      0.1      print("Computing Stage Costs...")
    46         1         54.0     54.0      0.0      SC_start_time = time.perf_counter()
    47         1       3207.0   3207.0      0.1      Q = compute_expected_stage_cost_fast(C, K)
    48         1         25.0     25.0      0.0      SC_end_time = time.perf_counter()
    49                                           
    50                                               # --- iGMRES & Solver Parameters ---
    51         1        145.0    145.0      0.0      K, L = C.K, C.L
    52         1          9.0      9.0      0.0      gamma = 1.0
    53         1         21.0     21.0      0.0      dtype = np.float64
    54                                           
    55         1        519.0    519.0      0.0      J = np.zeros(K, dtype=dtype)
    56         1         84.0     84.0      0.0      policy = np.zeros(K, dtype=int)
    57                                           
    58                                               # Tolerances
    59         1         10.0     10.0      0.0      gmres_tol_max = 1e-5
    60         1          6.0      6.0      0.0      gmres_tol_min = 1e-9
    61         1          8.0      8.0      0.0      eta = 0.5
    62         1          9.0      9.0      0.0      outer_tol = 1e-7
    63                                           
    64                                               # Iteration limits
    65         1          7.0      7.0      0.0      max_outer_iters = 200
    66         1          8.0      8.0      0.0      gmres_restart = 60
    67         1          8.0      8.0      0.0      max_inner_iters = 15
    68                                           
    69         1          7.0      7.0      0.0      delta_J_prev = 1.0
    70         1        323.0    323.0      0.0      range_k = np.arange(K, dtype=int) # Pre-compute for slicing
    71                                           
    72         1         16.0     16.0      0.0      start_time = time.perf_counter()
    73                                           
    74         1      30270.0  30270.0      1.2      A_all = build_A_fast_setup(K, L, P_stack, gamma, dtype)
    75                                           
    76                                               # Begin iterations
    77        31        270.0      8.7      0.0      for outer_iter in range(max_outer_iters):
    78        31       2038.0     65.7      0.1          J_prev = J.copy()
    79                                           
    80                                                   # --- 1. Build A (Optimized) ---
    81                                                   # A_sparse = build_A(K, P_stack, policy, range_k, gamma, dtype)
    82        31     178753.0   5766.2      7.1          A_sparse = build_A_fast(A_all, K, policy, range_k)
    83                                           
    84                                                   # --- 2. Preconditioner ---
    85        31      46654.0   1505.0      1.8          M = make_preconditioner(A_sparse, omega=0.8, inner_iters=3, dtype=dtype)
    86                                           
    87                                                   # Right-hand side
    88        31      21387.0    689.9      0.8          b = Q[range_k, policy].astype(dtype)
    89                                           
    90                                                   # Adaptive GMRES Tolerance
    91                                                   # If delta_J is large, we don't need a perfect linear solve yet.
    92        31        282.0      9.1      0.0          if outer_iter > 0:
    93        30        368.0     12.3      0.0              tol_k = eta * delta_J_prev
    94                                                   else:
    95         1          6.0      6.0      0.0              tol_k = gmres_tol_max
    96                                           
    97        31        692.0     22.3      0.0          tol_k = min(max(tol_k, gmres_tol_min), gmres_tol_max)
    98                                           
    99                                                   # --- 3. Solve Linear System ---
   100        31        394.0     12.7      0.0          try:
   101        62    1814967.0  29273.7     71.9              J_eval, info = spla.gmres(
   102        31        166.0      5.4      0.0                  A_sparse,
   103        31        162.0      5.2      0.0                  b,
   104        31        147.0      4.7      0.0                  x0=J,
   105        31        141.0      4.5      0.0                  tol=tol_k,
   106        31        159.0      5.1      0.0                  restart=gmres_restart,
   107        31        146.0      4.7      0.0                  maxiter=max_inner_iters,
   108        31        135.0      4.4      0.0                  M=M
   109                                                       )
   110        31        389.0     12.5      0.0              if info != 0:
   111                                                           J_eval = spla.spsolve(A_sparse, b)
   112                                                   except Exception:
   113                                                       J_eval = spla.spsolve(A_sparse, b)
   114                                           
   115                                                   # --- 4. Policy Improvement (Optimized) ---
   116        31      34535.0   1114.0      1.4          P_J_all = P_stack.dot(J_eval)
   117                                           
   118        31       1284.0     41.4      0.1          expected_future_costs = P_J_all.reshape((L, K)).T
   119                                           
   120                                                   # Bellman update
   121        31      27397.0    883.8      1.1          Q_J = Q + gamma * expected_future_costs
   122                                           
   123                                                   # Greedy improvement
   124        31      51851.0   1672.6      2.1          new_policy = np.argmin(Q_J, axis=1)
   125                                           
   126                                                   # Stats
   127        31      14402.0    464.6      0.6          policy_changes = np.sum(new_policy != policy)
   128        31      10484.0    338.2      0.4          delta_J = np.max(np.abs(J_eval - J_prev))
   129                                           
   130        31        191.0      6.2      0.0          delta_J_prev = delta_J
   131        31        375.0     12.1      0.0          J = J_eval
   132        31        279.0      9.0      0.0          policy = new_policy
   133                                           
   134        31        445.0     14.4      0.0          if policy_changes == 0 and delta_J < outer_tol:
   135         1       1852.0   1852.0      0.1              print(f"Converged in {outer_iter+1} iterations.")
   136         1         12.0     12.0      0.0              break
   137                                               else:
   138                                                   print("Warning: Max outer iterations reached without convergence.")
   139                                           
   140         1         42.0     42.0      0.0      end_time = time.perf_counter()
   141                                           
   142         1         18.0     18.0      0.0      T_TP = T_end_time - T_start_time
   143         1          9.0      9.0      0.0      T_SC = SC_end_time - SC_start_time
   144         1          8.0      8.0      0.0      T_J = end_time - start_time
   145         1         15.0     15.0      0.0      Total_time = time.perf_counter() - Total_start
   146                                           
   147         1       1227.0   1227.0      0.0      print("\n--- Timing Summary (Optimized with Slicing) ---")
   148         1       1667.0   1667.0      0.1      print(f"Transition Probabilities: {T_TP:.6f}s")
   149         1       1343.0   1343.0      0.1      print(f"Stage Costs:              {T_SC:.6f}s")
   150         1       1363.0   1363.0      0.1      print(f"Policy Iteration:         {T_J:.6f}s")
   151         1       1541.0   1541.0      0.1      print(f"Total Runtime:            {Total_time:.6f}s")
   152                                           
   153         1         19.0     19.0      0.0      return J, policy

Total time: 0.0243494 s
File: C:\Users\tobyt\OneDrive\ETH OneDrive_Personal\Master\DPOC\DPOC_Exercise\utils.py
Function: compute_transition_probabilities_vectorized at line 232

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   232                                           def compute_transition_probabilities_vectorized(C):
   233                                               """
   234                                               Optimized transition probability calculation using Coordinate Hashing.
   235                                               
   236                                               Improvements:
   237                                               1. Coordinate Hashing: Maps (y, v, d, h) -> Integer Index in O(1).
   238                                                  Replaces np.searchsorted (O(N log N)).
   239                                               2. Vectorized Physics: Strictly follows PDF dynamics (Collision, Spawning, Motion).
   240                                               """
   241                                           
   242                                               # 1. Parse State Space & Setup Hashing
   243                                               # ---------------------------------------------------------
   244         1      43808.0  43808.0     18.0      S_arr = np.array(C.state_space, dtype=np.int32)
   245         1         59.0     59.0      0.0      N = S_arr.shape[0]
   246         1         16.0     16.0      0.0      num_cols = S_arr.shape[1]
   247                                           
   248                                               # Calculate ranges and strides for Perfect Hashing
   249                                               # We map every state to a unique integer: Hash = Sum( (val - min) * stride )
   250         1       5498.0   5498.0      2.3      mins = S_arr.min(axis=0)
   251         1       3108.0   3108.0      1.3      maxs = S_arr.max(axis=0)
   252         1        486.0    486.0      0.2      ranges = maxs - mins + 1
   253                                               
   254                                               # Compute strides (column-major-like logic, but order doesn't matter as long as consistent)
   255         1         79.0     79.0      0.0      strides = np.zeros(num_cols, dtype=np.int64)
   256         1         10.0     10.0      0.0      current_stride = 1
   257         7        102.0     14.6      0.0      for i in range(num_cols):
   258         6         86.0     14.3      0.0          strides[i] = current_stride
   259         6        124.0     20.7      0.1          current_stride *= ranges[i]
   260                                           
   261                                               # Total size of the dense lookup table
   262         1          8.0      8.0      0.0      table_size = current_stride
   263                                               
   264                                               # Safety Check: If table is > 100MB (approx 25M entries), warn or fallback.
   265                                               # For Flappy Bird, table_size is usually < 5,000,000 (20MB), which is fine.
   266                                               
   267                                               # Create the lookup table
   268                                               # lookup_table[hash] = index_in_state_space
   269         1       3662.0   3662.0      1.5      lookup_table = np.full(table_size, -1, dtype=np.int32)
   270                                               
   271                                               # Compute hashes for all existing valid states
   272                                               # Formula: sum((S_arr[:, i] - mins[i]) * strides[i])
   273         1       4357.0   4357.0      1.8      state_hashes = np.dot((S_arr - mins), strides)
   274         1        653.0    653.0      0.3      lookup_table[state_hashes] = np.arange(N, dtype=np.int32)
   275                                           
   276                                               # Helper for O(1) Lookup
   277         1         38.0     38.0      0.0      def get_state_indices(next_states):
   278                                                   # 1. Check bounds (vectorized)
   279                                                   # Any state component outside [min, max] is invalid
   280                                                   valid_bounds = np.all((next_states >= mins) & (next_states <= maxs), axis=1)
   281                                                   
   282                                                   indices = np.full(next_states.shape[0], -1, dtype=np.int32)
   283                                                   
   284                                                   if np.any(valid_bounds):
   285                                                       # 2. Compute Hashes
   286                                                       # Subset only valid bounds to avoid overflow/segfaults on hash calculation
   287                                                       valid_states = next_states[valid_bounds]
   288                                                       hashes = np.dot((valid_states - mins), strides)
   289                                                       
   290                                                       # 3. Lookup
   291                                                       # Since we checked bounds, hashes are guaranteed < table_size
   292                                                       found_indices = lookup_table[hashes]
   293                                                       indices[valid_bounds] = found_indices
   294                                                       
   295                                                   # Return indices and a boolean mask of which ones were found
   296                                                   mask_found = (indices != -1)
   297                                                   return indices[mask_found], mask_found
   298                                           
   299                                               # 2. Pre-process State Columns
   300                                               # ---------------------------------------------------------
   301         1         26.0     26.0      0.0      Y = S_arr[:, 0]
   302         1         18.0     18.0      0.0      V = S_arr[:, 1]
   303         1        106.0    106.0      0.0      D = S_arr[:, 2 : 2 + C.M]
   304         1         57.0     57.0      0.0      H = S_arr[:, 2 + C.M : 2 + 2 * C.M]
   305                                           
   306                                               # Collision Logic (PDF: "transition to a cost-free termination state")
   307                                               # We treat these as absorbing (rows of 0 in P), effectively removing them from the game flow.
   308         1         30.0     30.0      0.0      if C.M > 0:
   309         1         11.0     11.0      0.0          gap_tol = (C.G - 1) // 2
   310                                                   # Collision if inside pipe horizontally (D=0) AND outside gap vertically
   311         1       1281.0   1281.0      0.5          is_collided = (D[:, 0] == 0) & (np.abs(Y - H[:, 0]) > gap_tol)
   312                                               else:
   313                                                   is_collided = np.zeros(N, dtype=bool)
   314                                           
   315                                               # 3. Deterministic Pipe Dynamics (Pre-calculated)
   316                                               # ---------------------------------------------------------
   317         1        682.0    682.0      0.3      Hat_D = D.copy()
   318         1        915.0    915.0      0.4      Hat_H = H.copy()
   319                                           
   320         1         42.0     42.0      0.0      if C.M > 0:
   321                                                   # Mask: Pipes that are currently at x=0 (Passing/Recycling)
   322         1        116.0    116.0      0.0          mask_passing = (D[:, 0] == 0)
   323                                                   
   324                                                   # Shift pipes left
   325         1         30.0     30.0      0.0          if C.M > 1:
   326         1        859.0    859.0      0.4              Hat_D[mask_passing, :-1] = D[mask_passing, 1:]
   327         1        627.0    627.0      0.3              Hat_H[mask_passing, :-1] = H[mask_passing, 1:]
   328                                                   
   329                                                   # Reset last pipe (will be filled by spawn logic if applicable)
   330         1        335.0    335.0      0.1          Hat_D[mask_passing, C.M-1] = 0
   331         1         35.0     35.0      0.0          if len(C.S_h) > 0:
   332         1        330.0    330.0      0.1              Hat_H[mask_passing, C.M-1] = C.S_h[0] # Default height
   333                                           
   334                                                   # Decrement horizontal distance (Drift)
   335                                                   # Only decrement if not just reset (checked by > 0)
   336         1        109.0    109.0      0.0          mask_dec = (Hat_D[:, 0] > 0)
   337         1       1490.0   1490.0      0.6          Hat_D[mask_dec, 0] -= 1
   338                                           
   339                                               # Spawn Probability Logic (Linear Ramp)
   340         1       1897.0   1897.0      0.8      sum_hat_D = np.sum(Hat_D, axis=1)
   341         1        104.0    104.0      0.0      s_values = (C.X - 1) - sum_hat_D # Free space
   342                                               
   343                                               # p = (s - (Dmin-1)) / (X - Dmin)
   344         1         87.0     87.0      0.0      numerator = s_values - (C.D_min - 1)
   345         1         28.0     28.0      0.0      denominator = float(C.X - C.D_min)
   346         1        741.0    741.0      0.3      p_spawn_vec = np.clip(numerator / denominator, 0.0, 1.0)
   347                                               
   348                                               # Identify which pipe index 'k' to spawn into (first available slot)
   349         1        212.0    212.0      0.1      k_spawn_indices = np.full(N, C.M - 1, dtype=int)
   350         1         30.0     30.0      0.0      if C.M > 1:
   351                                                   # Find first column where D=0
   352         1        154.0    154.0      0.1          is_zero = (Hat_D[:, 1:] == 0)
   353         1        437.0    437.0      0.2          any_zero = np.any(is_zero, axis=1)
   354         1        928.0    928.0      0.4          first_zero = np.argmax(is_zero, axis=1)
   355         1        353.0    353.0      0.1          k_spawn_indices[any_zero] = first_zero[any_zero] + 1
   356                                           
   357                                               # 4. Input Loop & Matrix Construction
   358                                               # ---------------------------------------------------------
   359         1         38.0     38.0      0.0      prob_h_new = 1.0 / len(C.S_h) if len(C.S_h) > 0 else 0.0
   360         1        113.0    113.0      0.0      U_array = np.array(C.input_space)
   361                                               
   362         1          7.0      7.0      0.0      P_sparse_list = []
   363                                           
   364         4         98.0     24.5      0.0      for u in U_array:
   365                                                   # Initialize Coordinate Lists for Sparse Matrix
   366         3         63.0     21.0      0.0          rows_list = []
   367         3         41.0     13.7      0.0          cols_list = []
   368         3         45.0     15.0      0.0          data_list = []
   369                                                   
   370                                                   # Resolve Flap/Wind randomness
   371         3         51.0     17.0      0.0          if u == C.U_strong:
   372         1         47.0     47.0      0.0              W_flap = np.arange(-C.V_dev, C.V_dev + 1)
   373                                                   else:
   374         2         56.0     28.0      0.0              W_flap = np.array([0])
   375                                                   
   376         3         60.0     20.0      0.0          prob_flap = 1.0 / len(W_flap)
   377         3         30.0     10.0      0.0          n_w = len(W_flap)
   378                                           
   379                                                   # Vectorized Next State Calculation
   380                                                   # v_{k+1} = v_k + u + w - g
   381                                                   # Broadcast: (N, 1) + scalar + (1, n_w) -> (N, n_w)
   382         3       2925.0    975.0      1.2          V_next_matrix = V[:, None] + u + W_flap[None, :] - C.g
   383         3        870.0    290.0      0.4          V_next_flat = np.clip(V_next_matrix, -C.V_max, C.V_max).flatten()
   384                                                   
   385                                                   # y_{k+1} = y_k + v_k (Note: Uses CURRENT v_k)
   386         3       3034.0   1011.3      1.2          Y_repeated = np.repeat(Y, n_w)
   387         3       2938.0    979.3      1.2          V_curr_repeated = np.repeat(V, n_w)
   388         3       1486.0    495.3      0.6          Y_next_flat = np.clip(Y_repeated + V_curr_repeated, 0, C.Y - 1).astype(np.int32)
   389                                                   
   390                                                   # Filter Collided Sources (They don't transition)
   391         3       2807.0    935.7      1.2          source_idxs_base = np.repeat(np.arange(N), n_w)
   392         3       2971.0    990.3      1.2          valid_src_mask = ~np.repeat(is_collided, n_w)
   393                                                   
   394                                                   # Apply mask
   395         3        402.0    134.0      0.2          V_next = V_next_flat[valid_src_mask]
   396         3        603.0    201.0      0.2          Y_next = Y_next_flat[valid_src_mask]
   397         3        608.0    202.7      0.2          src_idxs = source_idxs_base[valid_src_mask]
   398                                                   
   399                                                   # Get pipe state for these sources
   400         3       5523.0   1841.0      2.3          Hat_D_sub = Hat_D[src_idxs]
   401         3       4922.0   1640.7      2.0          Hat_H_sub = Hat_H[src_idxs]
   402         3       1754.0    584.7      0.7          p_spawn_sub = p_spawn_vec[src_idxs]
   403                                                   
   404                                                   # --- PATH A: NO SPAWN ---
   405                                                   # Prob = prob_flap * (1 - p_spawn)
   406         3       1159.0    386.3      0.5          probs_ns = prob_flap * (1.0 - p_spawn_sub)
   407         3        340.0    113.3      0.1          mask_ns = probs_ns > 0
   408                                                   
   409         3       1043.0    347.7      0.4          if np.any(mask_ns):
   410                                                       # Construct Next States Matrix
   411         6       7692.0   1282.0      3.2              NS_states = np.column_stack((
   412         3        552.0    184.0      0.2                  Y_next[mask_ns], 
   413         3        273.0     91.0      0.1                  V_next[mask_ns], 
   414         3       6485.0   2161.7      2.7                  Hat_D_sub[mask_ns], 
   415         3       5580.0   1860.0      2.3                  Hat_H_sub[mask_ns]
   416                                                       ))
   417                                                       
   418                                                       # FAST LOOKUP via Hashing
   419         3      32524.0  10841.3     13.4              dest_idxs, found = get_state_indices(NS_states)
   420                                                       
   421         3         68.0     22.7      0.0              if len(dest_idxs) > 0:
   422         3        517.0    172.3      0.2                  rows_list.append(src_idxs[mask_ns][found])
   423         3         31.0     10.3      0.0                  cols_list.append(dest_idxs)
   424         3        593.0    197.7      0.2                  data_list.append(probs_ns[mask_ns][found])
   425                                           
   426                                                   # --- PATH B: SPAWN ---
   427         3        580.0    193.3      0.2          mask_s = (p_spawn_sub > 0)
   428         3       1406.0    468.7      0.6          if np.any(mask_s) and len(C.S_h) > 0:
   429                                                       # Subset for spawn calculations
   430         3        311.0    103.7      0.1              S_Y = Y_next[mask_s]
   431         3        264.0     88.0      0.1              S_V = V_next[mask_s]
   432         3        235.0     78.3      0.1              S_src = src_idxs[mask_s]
   433         3       1397.0    465.7      0.6              S_D = Hat_D_sub[mask_s]
   434         3       1293.0    431.0      0.5              S_H = Hat_H_sub[mask_s]
   435         3       1196.0    398.7      0.5              S_k = k_spawn_indices[src_idxs][mask_s]
   436                                                       
   437                                                       # Base probability for this branch
   438         3        454.0    151.3      0.2              S_base_prob = prob_flap * p_spawn_sub[mask_s]
   439                                                       
   440                                                       # Calculate 's' distance to fill
   441                                                       # s = X - 1 - sum(d)
   442         3       2744.0    914.7      1.1              S_s_fill = np.clip((C.X - 1) - np.sum(S_D, axis=1), C.D_min, C.X - 1)
   443                                           
   444                                                       # Iterate over possible new heights (Uniform probability)
   445        12        112.0      9.3      0.0              for h_new in C.S_h:
   446                                                           # Construct new pipe arrays
   447         9        322.0     35.8      0.1                  D_new = S_D.copy()
   448         9        289.0     32.1      0.1                  H_new = S_H.copy()
   449                                                           
   450                                                           # Update the specific pipe k
   451         9        638.0     70.9      0.3                  row_indices = np.arange(len(S_Y))
   452         9       2701.0    300.1      1.1                  D_new[row_indices, S_k] = S_s_fill
   453         9       2296.0    255.1      0.9                  H_new[row_indices, S_k] = h_new
   454                                                           
   455                                                           # Construct State Matrix
   456         9       6231.0    692.3      2.6                  S_states = np.column_stack((S_Y, S_V, D_new, H_new))
   457                                                           
   458                                                           # FAST LOOKUP
   459         9      21666.0   2407.3      8.9                  dest_idxs, found = get_state_indices(S_states)
   460                                                           
   461         9        132.0     14.7      0.1                  if len(dest_idxs) > 0:
   462         9        413.0     45.9      0.2                      rows_list.append(S_src[found])
   463         9         77.0      8.6      0.0                      cols_list.append(dest_idxs)
   464                                                               # p = base_prob * (1/|Sh|)
   465         9        761.0     84.6      0.3                      data_list.append(S_base_prob[found] * prob_h_new)
   466                                           
   467                                                   # Build CSR Matrix for this input u
   468         3         42.0     14.0      0.0          if len(data_list) > 0:
   469         3        675.0    225.0      0.3              data = np.concatenate(data_list)
   470         3        261.0     87.0      0.1              rows = np.concatenate(rows_list)
   471         3        510.0    170.0      0.2              cols = np.concatenate(cols_list)
   472         3      33924.0  11308.0     13.9              P_mat = sp.csr_matrix((data, (rows, cols)), shape=(C.K, C.K))
   473                                                   else:
   474                                                       P_mat = sp.csr_matrix((C.K, C.K))
   475                                                       
   476         3         47.0     15.7      0.0          P_sparse_list.append(P_mat)
   477                                           
   478         1          4.0      4.0      0.0      return P_sparse_list

