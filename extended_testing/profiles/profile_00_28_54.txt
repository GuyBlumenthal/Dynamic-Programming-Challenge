Timer unit: 1e-07 s

Total time: 0.404184 s
File: C:\Users\tobyt\OneDrive\ETH OneDrive_Personal\Master\DPOC\DPOC_Exercise\Solver.py
Function: solution at line 31

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    31                                           def solution(C: Const) -> tuple[np.ndarray, np.ndarray]:
    32                                               # 1. Setup Phase
    33                                               # -----------------------------------------------------
    34         1        196.0    196.0      0.0      Total_start = time.perf_counter()
    35         1       2287.0   2287.0      0.1      print("Computing Transition Probabilities... (Optimized Hashing)")
    36                                               
    37         1         40.0     40.0      0.0      T_start = time.perf_counter()
    38                                               # Call the optimized function from utils.py
    39         1     251149.0 251149.0      6.2      P_list = compute_transition_probabilities_vectorized(C)
    40                                               
    41                                               # Convert to CSR immediately for fast arithmetic
    42         1        235.0    235.0      0.0      P_actions = [p.tocsr() for p in P_list]
    43                                               
    44                                               # Pre-compute stacked version for Cost calculation (P_stack @ J)
    45         1       7433.0   7433.0      0.2      P_stack = sp.vstack(P_actions).tocsr()
    46         1         35.0     35.0      0.0      T_end = time.perf_counter()
    47                                           
    48         1       2043.0   2043.0      0.1      print("Computing Stage Costs...")
    49                                               # Assuming standard fast cost computation
    50         1       3453.0   3453.0      0.1      Q = compute_expected_stage_cost_fast(C, C.K)
    51                                               
    52                                               # 2. Solver Parameters
    53                                               # -----------------------------------------------------
    54         1        209.0    209.0      0.0      K, L = C.K, C.L
    55         1         18.0     18.0      0.0      gamma = 1.0
    56         1         30.0     30.0      0.0      dtype = np.float64
    57                                               
    58                                               # Initialization
    59         1        690.0    690.0      0.0      J = np.zeros(K, dtype=dtype)
    60         1        191.0    191.0      0.0      policy = np.zeros(K, dtype=int)
    61                                               
    62                                               # Pre-allocate range for indexing
    63         1        531.0    531.0      0.0      range_k = np.arange(K, dtype=int)
    64                                               
    65                                               # Pre-build Identity matrix (CSR)
    66         1       3190.0   3190.0      0.1      I_mat = sp.eye(K, format='csr', dtype=dtype)
    67                                           
    68                                               # Tuning for GMRES speed
    69                                               # We use a loose tolerance initially and tighten it only if needed (adaptive)
    70         1         10.0     10.0      0.0      max_outer_iters = 200
    71         1          6.0      6.0      0.0      outer_tol = 1e-7
    72         1         10.0     10.0      0.0      gmres_tol_max = 1e-4
    73         1          5.0      5.0      0.0      gmres_tol_min = 1e-8
    74         1         11.0     11.0      0.0      gmres_restart = 60
    75         1          3.0      3.0      0.0      max_inner_iters = 30 # Higher inner iters = fewer restarts = faster
    76                                           
    77         1          3.0      3.0      0.0      delta_J_prev = 1.0
    78                                               
    79         1         14.0     14.0      0.0      solve_start = time.perf_counter()
    80                                           
    81                                               # 3. Policy Iteration Loop
    82                                               # -----------------------------------------------------
    83        23        219.0      9.5      0.0      for outer_iter in range(max_outer_iters):
    84        23       2074.0     90.2      0.1          J_prev = J.copy()
    85                                           
    86                                                   # --- A. Optimized Matrix Construction (Masking) ---
    87                                                   # Goal: Construct A = I - gamma * P_pi
    88                                                   # Method: P_pi = Mask_0 * P_0 + Mask_1 * P_1 ...
    89                                                   # This is much faster than slicing rows in Python.
    90                                                   
    91        23      55421.0   2409.6      1.4          P_pi_accum = sp.csr_matrix((K, K), dtype=dtype)
    92                                                   
    93        92       1057.0     11.5      0.0          for l in range(L):
    94                                                       # Boolean array where policy chooses action l
    95        69       8067.0    116.9      0.2              is_action_l = (policy == l)
    96                                                       
    97                                                       # Skip if action is not used
    98        69      16376.0    237.3      0.4              if not np.any(is_action_l):
    99         2          8.0      4.0      0.0                  continue
   100                                                           
   101                                                       # Create diagonal mask matrix
   102                                                       # casting boolean to int/float creates 0s and 1s on diagonal
   103        67     589591.0   8799.9     14.6              Mask_l = sp.diags(is_action_l.astype(dtype), format='csr')
   104                                                       
   105                                                       # Add to accumulator: Mask * P_l (Efficient C-level sparse mult)
   106        67     655174.0   9778.7     16.2              P_pi_accum += Mask_l.dot(P_actions[l])
   107                                                   
   108                                                   # A = I - gamma * P_pi
   109        23     153774.0   6685.8      3.8          A_sparse = I_mat - gamma * P_pi_accum
   110                                           
   111                                                   # --- B. Preconditioner ---
   112                                                   # Simple Jacobi/ILU approximation helps GMRES converge faster
   113                                                   # Recomputing every step is cheap enough compared to the solve
   114        23      34822.0   1514.0      0.9          M_precond = make_preconditioner(A_sparse, omega=0.8, inner_iters=3, dtype=dtype)
   115                                           
   116                                                   # --- C. Right-Hand Side ---
   117        23      17008.0    739.5      0.4          b = Q[range_k, policy].astype(dtype)
   118                                           
   119                                                   # --- D. Adaptive Tolerance ---
   120                                                   # If we are far from convergence (high delta), we don't need a precise linear solve.
   121        23        188.0      8.2      0.0          if outer_iter > 0:
   122        22        344.0     15.6      0.0              tol_k = 0.5 * delta_J_prev 
   123                                                   else:
   124         1          5.0      5.0      0.0              tol_k = gmres_tol_max
   125        23        558.0     24.3      0.0          tol_k = min(max(tol_k, gmres_tol_min), gmres_tol_max)
   126                                           
   127                                                   # --- E. Linear Solve (GMRES) ---
   128        23        113.0      4.9      0.0          try:
   129        46    2106936.0  45803.0     52.1              J_eval, info = spla.gmres(
   130        23        114.0      5.0      0.0                  A_sparse, b, x0=J, 
   131        23         98.0      4.3      0.0                  tol=tol_k, 
   132        23        119.0      5.2      0.0                  restart=gmres_restart, 
   133        23        107.0      4.7      0.0                  maxiter=max_inner_iters, 
   134        23         92.0      4.0      0.0                  M=M_precond
   135                                                       )
   136        23        296.0     12.9      0.0              if info != 0:
   137                                                           # Fallback to direct solve if GMRES fails (rare)
   138                                                           J_eval = spla.spsolve(A_sparse, b)
   139                                                   except Exception:
   140                                                       J_eval = spla.spsolve(A_sparse, b)
   141                                           
   142                                                   # --- F. Policy Improvement ---
   143                                                   # Compute Expected Future Costs for ALL actions simultaneously
   144                                                   # P_stack is (L*K, K). J is (K,). Result is (L*K,).
   145        23      30928.0   1344.7      0.8          P_J_all = P_stack.dot(J_eval)
   146                                                   
   147                                                   # Reshape to (L, K) -> Transpose to (K, L)
   148                                                   # Row k contains [Cost_Act0, Cost_Act1, ...]
   149        23       1256.0     54.6      0.0          future_costs = P_J_all.reshape((L, K)).T
   150                                                   
   151        23      27867.0   1211.6      0.7          Q_J = Q + gamma * future_costs
   152                                                   
   153                                                   # Greedy Update
   154        23      38120.0   1657.4      0.9          new_policy = np.argmin(Q_J, axis=1)
   155                                           
   156                                                   # --- G. Convergence Check ---
   157        23      13151.0    571.8      0.3          policy_changes = np.sum(new_policy != policy)
   158        23      10163.0    441.9      0.3          delta_J = np.max(np.abs(J_eval - J_prev))
   159                                           
   160        23        139.0      6.0      0.0          delta_J_prev = delta_J
   161        23        337.0     14.7      0.0          J = J_eval
   162        23        246.0     10.7      0.0          policy = new_policy
   163                                           
   164        23        320.0     13.9      0.0          if policy_changes == 0 and delta_J < outer_tol:
   165         1       1629.0   1629.0      0.0              print(f"Converged in {outer_iter+1} iterations.")
   166         1         12.0     12.0      0.0              break
   167                                                   
   168        22        337.0     15.3      0.0          if outer_iter == max_outer_iters - 1:
   169                                                       print("Warning: Max outer iterations reached without convergence.")
   170                                           
   171                                               # 4. Final Timing Stats
   172                                               # -----------------------------------------------------
   173         1         47.0     47.0      0.0      Total_time = time.perf_counter() - Total_start
   174         1          7.0      7.0      0.0      T_setup = T_end - T_start
   175         1         11.0     11.0      0.0      T_solve = time.perf_counter() - solve_start
   176                                               
   177         1       1050.0   1050.0      0.0      print("\n--- Timing Summary (Fully Optimized) ---")
   178         1        618.0    618.0      0.0      print(f"Transition Setup (Hashing): {T_setup:.6f}s")
   179         1        584.0    584.0      0.0      print(f"Solver Loop (Masking):      {T_solve:.6f}s")
   180         1        645.0    645.0      0.0      print(f"Total Runtime:              {Total_time:.6f}s")
   181                                           
   182         1         17.0     17.0      0.0      return J, policy

Total time: 0.0242047 s
File: C:\Users\tobyt\OneDrive\ETH OneDrive_Personal\Master\DPOC\DPOC_Exercise\utils.py
Function: compute_transition_probabilities_vectorized at line 232

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   232                                           def compute_transition_probabilities_vectorized(C):
   233                                               """
   234                                               Optimized transition probability calculation using Coordinate Hashing.
   235                                               
   236                                               Improvements:
   237                                               1. Coordinate Hashing: Maps (y, v, d, h) -> Integer Index in O(1).
   238                                                  Replaces np.searchsorted (O(N log N)).
   239                                               2. Vectorized Physics: Strictly follows PDF dynamics (Collision, Spawning, Motion).
   240                                               """
   241                                           
   242                                               # 1. Parse State Space & Setup Hashing
   243                                               # ---------------------------------------------------------
   244         1      44333.0  44333.0     18.3      S_arr = np.array(C.state_space, dtype=np.int32)
   245         1         84.0     84.0      0.0      N = S_arr.shape[0]
   246         1         16.0     16.0      0.0      num_cols = S_arr.shape[1]
   247                                           
   248                                               # Calculate ranges and strides for Perfect Hashing
   249                                               # We map every state to a unique integer: Hash = Sum( (val - min) * stride )
   250         1       3699.0   3699.0      1.5      mins = S_arr.min(axis=0)
   251         1       2602.0   2602.0      1.1      maxs = S_arr.max(axis=0)
   252         1        272.0    272.0      0.1      ranges = maxs - mins + 1
   253                                               
   254                                               # Compute strides (column-major-like logic, but order doesn't matter as long as consistent)
   255         1         72.0     72.0      0.0      strides = np.zeros(num_cols, dtype=np.int64)
   256         1         10.0     10.0      0.0      current_stride = 1
   257         7         93.0     13.3      0.0      for i in range(num_cols):
   258         6         84.0     14.0      0.0          strides[i] = current_stride
   259         6        106.0     17.7      0.0          current_stride *= ranges[i]
   260                                           
   261                                               # Total size of the dense lookup table
   262         1          8.0      8.0      0.0      table_size = current_stride
   263                                               
   264                                               # Safety Check: If table is > 100MB (approx 25M entries), warn or fallback.
   265                                               # For Flappy Bird, table_size is usually < 5,000,000 (20MB), which is fine.
   266                                               
   267                                               # Create the lookup table
   268                                               # lookup_table[hash] = index_in_state_space
   269         1       3591.0   3591.0      1.5      lookup_table = np.full(table_size, -1, dtype=np.int32)
   270                                               
   271                                               # Compute hashes for all existing valid states
   272                                               # Formula: sum((S_arr[:, i] - mins[i]) * strides[i])
   273         1       5099.0   5099.0      2.1      state_hashes = np.dot((S_arr - mins), strides)
   274         1        674.0    674.0      0.3      lookup_table[state_hashes] = np.arange(N, dtype=np.int32)
   275                                           
   276                                               # Helper for O(1) Lookup
   277         1         37.0     37.0      0.0      def get_state_indices(next_states):
   278                                                   # 1. Check bounds (vectorized)
   279                                                   # Any state component outside [min, max] is invalid
   280                                                   valid_bounds = np.all((next_states >= mins) & (next_states <= maxs), axis=1)
   281                                                   
   282                                                   indices = np.full(next_states.shape[0], -1, dtype=np.int32)
   283                                                   
   284                                                   if np.any(valid_bounds):
   285                                                       # 2. Compute Hashes
   286                                                       # Subset only valid bounds to avoid overflow/segfaults on hash calculation
   287                                                       valid_states = next_states[valid_bounds]
   288                                                       hashes = np.dot((valid_states - mins), strides)
   289                                                       
   290                                                       # 3. Lookup
   291                                                       # Since we checked bounds, hashes are guaranteed < table_size
   292                                                       found_indices = lookup_table[hashes]
   293                                                       indices[valid_bounds] = found_indices
   294                                                       
   295                                                   # Return indices and a boolean mask of which ones were found
   296                                                   mask_found = (indices != -1)
   297                                                   return indices[mask_found], mask_found
   298                                           
   299                                               # 2. Pre-process State Columns
   300                                               # ---------------------------------------------------------
   301         1         31.0     31.0      0.0      Y = S_arr[:, 0]
   302         1         17.0     17.0      0.0      V = S_arr[:, 1]
   303         1        104.0    104.0      0.0      D = S_arr[:, 2 : 2 + C.M]
   304         1         53.0     53.0      0.0      H = S_arr[:, 2 + C.M : 2 + 2 * C.M]
   305                                           
   306                                               # Collision Logic (PDF: "transition to a cost-free termination state")
   307                                               # We treat these as absorbing (rows of 0 in P), effectively removing them from the game flow.
   308         1         26.0     26.0      0.0      if C.M > 0:
   309         1         10.0     10.0      0.0          gap_tol = (C.G - 1) // 2
   310                                                   # Collision if inside pipe horizontally (D=0) AND outside gap vertically
   311         1        844.0    844.0      0.3          is_collided = (D[:, 0] == 0) & (np.abs(Y - H[:, 0]) > gap_tol)
   312                                               else:
   313                                                   is_collided = np.zeros(N, dtype=bool)
   314                                           
   315                                               # 3. Deterministic Pipe Dynamics (Pre-calculated)
   316                                               # ---------------------------------------------------------
   317         1        653.0    653.0      0.3      Hat_D = D.copy()
   318         1        904.0    904.0      0.4      Hat_H = H.copy()
   319                                           
   320         1         36.0     36.0      0.0      if C.M > 0:
   321                                                   # Mask: Pipes that are currently at x=0 (Passing/Recycling)
   322         1        115.0    115.0      0.0          mask_passing = (D[:, 0] == 0)
   323                                                   
   324                                                   # Shift pipes left
   325         1         26.0     26.0      0.0          if C.M > 1:
   326         1        947.0    947.0      0.4              Hat_D[mask_passing, :-1] = D[mask_passing, 1:]
   327         1        711.0    711.0      0.3              Hat_H[mask_passing, :-1] = H[mask_passing, 1:]
   328                                                   
   329                                                   # Reset last pipe (will be filled by spawn logic if applicable)
   330         1        340.0    340.0      0.1          Hat_D[mask_passing, C.M-1] = 0
   331         1         46.0     46.0      0.0          if len(C.S_h) > 0:
   332         1        331.0    331.0      0.1              Hat_H[mask_passing, C.M-1] = C.S_h[0] # Default height
   333                                           
   334                                                   # Decrement horizontal distance (Drift)
   335                                                   # Only decrement if not just reset (checked by > 0)
   336         1        113.0    113.0      0.0          mask_dec = (Hat_D[:, 0] > 0)
   337         1       1174.0   1174.0      0.5          Hat_D[mask_dec, 0] -= 1
   338                                           
   339                                               # Spawn Probability Logic (Linear Ramp)
   340         1       1840.0   1840.0      0.8      sum_hat_D = np.sum(Hat_D, axis=1)
   341         1         98.0     98.0      0.0      s_values = (C.X - 1) - sum_hat_D # Free space
   342                                               
   343                                               # p = (s - (Dmin-1)) / (X - Dmin)
   344         1         86.0     86.0      0.0      numerator = s_values - (C.D_min - 1)
   345         1         30.0     30.0      0.0      denominator = float(C.X - C.D_min)
   346         1        707.0    707.0      0.3      p_spawn_vec = np.clip(numerator / denominator, 0.0, 1.0)
   347                                               
   348                                               # Identify which pipe index 'k' to spawn into (first available slot)
   349         1        219.0    219.0      0.1      k_spawn_indices = np.full(N, C.M - 1, dtype=int)
   350         1         31.0     31.0      0.0      if C.M > 1:
   351                                                   # Find first column where D=0
   352         1        157.0    157.0      0.1          is_zero = (Hat_D[:, 1:] == 0)
   353         1        427.0    427.0      0.2          any_zero = np.any(is_zero, axis=1)
   354         1        893.0    893.0      0.4          first_zero = np.argmax(is_zero, axis=1)
   355         1        354.0    354.0      0.1          k_spawn_indices[any_zero] = first_zero[any_zero] + 1
   356                                           
   357                                               # 4. Input Loop & Matrix Construction
   358                                               # ---------------------------------------------------------
   359         1         31.0     31.0      0.0      prob_h_new = 1.0 / len(C.S_h) if len(C.S_h) > 0 else 0.0
   360         1        107.0    107.0      0.0      U_array = np.array(C.input_space)
   361                                               
   362         1          8.0      8.0      0.0      P_sparse_list = []
   363                                           
   364         4        101.0     25.2      0.0      for u in U_array:
   365                                                   # Initialize Coordinate Lists for Sparse Matrix
   366         3         56.0     18.7      0.0          rows_list = []
   367         3         34.0     11.3      0.0          cols_list = []
   368         3         39.0     13.0      0.0          data_list = []
   369                                                   
   370                                                   # Resolve Flap/Wind randomness
   371         3         38.0     12.7      0.0          if u == C.U_strong:
   372         1         48.0     48.0      0.0              W_flap = np.arange(-C.V_dev, C.V_dev + 1)
   373                                                   else:
   374         2         54.0     27.0      0.0              W_flap = np.array([0])
   375                                                   
   376         3         40.0     13.3      0.0          prob_flap = 1.0 / len(W_flap)
   377         3         23.0      7.7      0.0          n_w = len(W_flap)
   378                                           
   379                                                   # Vectorized Next State Calculation
   380                                                   # v_{k+1} = v_k + u + w - g
   381                                                   # Broadcast: (N, 1) + scalar + (1, n_w) -> (N, n_w)
   382         3       2815.0    938.3      1.2          V_next_matrix = V[:, None] + u + W_flap[None, :] - C.g
   383         3        852.0    284.0      0.4          V_next_flat = np.clip(V_next_matrix, -C.V_max, C.V_max).flatten()
   384                                                   
   385                                                   # y_{k+1} = y_k + v_k (Note: Uses CURRENT v_k)
   386         3       2688.0    896.0      1.1          Y_repeated = np.repeat(Y, n_w)
   387         3       2517.0    839.0      1.0          V_curr_repeated = np.repeat(V, n_w)
   388         3       1935.0    645.0      0.8          Y_next_flat = np.clip(Y_repeated + V_curr_repeated, 0, C.Y - 1).astype(np.int32)
   389                                                   
   390                                                   # Filter Collided Sources (They don't transition)
   391         3       2662.0    887.3      1.1          source_idxs_base = np.repeat(np.arange(N), n_w)
   392         3       2655.0    885.0      1.1          valid_src_mask = ~np.repeat(is_collided, n_w)
   393                                                   
   394                                                   # Apply mask
   395         3        421.0    140.3      0.2          V_next = V_next_flat[valid_src_mask]
   396         3        346.0    115.3      0.1          Y_next = Y_next_flat[valid_src_mask]
   397         3        685.0    228.3      0.3          src_idxs = source_idxs_base[valid_src_mask]
   398                                                   
   399                                                   # Get pipe state for these sources
   400         3       6723.0   2241.0      2.8          Hat_D_sub = Hat_D[src_idxs]
   401         3       6386.0   2128.7      2.6          Hat_H_sub = Hat_H[src_idxs]
   402         3       2229.0    743.0      0.9          p_spawn_sub = p_spawn_vec[src_idxs]
   403                                                   
   404                                                   # --- PATH A: NO SPAWN ---
   405                                                   # Prob = prob_flap * (1 - p_spawn)
   406         3       1554.0    518.0      0.6          probs_ns = prob_flap * (1.0 - p_spawn_sub)
   407         3        639.0    213.0      0.3          mask_ns = probs_ns > 0
   408                                                   
   409         3       1137.0    379.0      0.5          if np.any(mask_ns):
   410                                                       # Construct Next States Matrix
   411         6       6856.0   1142.7      2.8              NS_states = np.column_stack((
   412         3        578.0    192.7      0.2                  Y_next[mask_ns], 
   413         3        413.0    137.7      0.2                  V_next[mask_ns], 
   414         3       6989.0   2329.7      2.9                  Hat_D_sub[mask_ns], 
   415         3       5225.0   1741.7      2.2                  Hat_H_sub[mask_ns]
   416                                                       ))
   417                                                       
   418                                                       # FAST LOOKUP via Hashing
   419         3      34190.0  11396.7     14.1              dest_idxs, found = get_state_indices(NS_states)
   420                                                       
   421         3         80.0     26.7      0.0              if len(dest_idxs) > 0:
   422         3        637.0    212.3      0.3                  rows_list.append(src_idxs[mask_ns][found])
   423         3         33.0     11.0      0.0                  cols_list.append(dest_idxs)
   424         3        684.0    228.0      0.3                  data_list.append(probs_ns[mask_ns][found])
   425                                           
   426                                                   # --- PATH B: SPAWN ---
   427         3        344.0    114.7      0.1          mask_s = (p_spawn_sub > 0)
   428         3       1054.0    351.3      0.4          if np.any(mask_s) and len(C.S_h) > 0:
   429                                                       # Subset for spawn calculations
   430         3        283.0     94.3      0.1              S_Y = Y_next[mask_s]
   431         3        273.0     91.0      0.1              S_V = V_next[mask_s]
   432         3        251.0     83.7      0.1              S_src = src_idxs[mask_s]
   433         3       1583.0    527.7      0.7              S_D = Hat_D_sub[mask_s]
   434         3       1527.0    509.0      0.6              S_H = Hat_H_sub[mask_s]
   435         3       1293.0    431.0      0.5              S_k = k_spawn_indices[src_idxs][mask_s]
   436                                                       
   437                                                       # Base probability for this branch
   438         3        531.0    177.0      0.2              S_base_prob = prob_flap * p_spawn_sub[mask_s]
   439                                                       
   440                                                       # Calculate 's' distance to fill
   441                                                       # s = X - 1 - sum(d)
   442         3       2178.0    726.0      0.9              S_s_fill = np.clip((C.X - 1) - np.sum(S_D, axis=1), C.D_min, C.X - 1)
   443                                           
   444                                                       # Iterate over possible new heights (Uniform probability)
   445        12        123.0     10.2      0.1              for h_new in C.S_h:
   446                                                           # Construct new pipe arrays
   447         9        317.0     35.2      0.1                  D_new = S_D.copy()
   448         9        252.0     28.0      0.1                  H_new = S_H.copy()
   449                                                           
   450                                                           # Update the specific pipe k
   451         9        506.0     56.2      0.2                  row_indices = np.arange(len(S_Y))
   452         9       2549.0    283.2      1.1                  D_new[row_indices, S_k] = S_s_fill
   453         9       2307.0    256.3      1.0                  H_new[row_indices, S_k] = h_new
   454                                                           
   455                                                           # Construct State Matrix
   456         9       4685.0    520.6      1.9                  S_states = np.column_stack((S_Y, S_V, D_new, H_new))
   457                                                           
   458                                                           # FAST LOOKUP
   459         9      21258.0   2362.0      8.8                  dest_idxs, found = get_state_indices(S_states)
   460                                                           
   461         9        137.0     15.2      0.1                  if len(dest_idxs) > 0:
   462         9        402.0     44.7      0.2                      rows_list.append(S_src[found])
   463         9         75.0      8.3      0.0                      cols_list.append(dest_idxs)
   464                                                               # p = base_prob * (1/|Sh|)
   465         9        772.0     85.8      0.3                      data_list.append(S_base_prob[found] * prob_h_new)
   466                                           
   467                                                   # Build CSR Matrix for this input u
   468         3         32.0     10.7      0.0          if len(data_list) > 0:
   469         3        351.0    117.0      0.1              data = np.concatenate(data_list)
   470         3        736.0    245.3      0.3              rows = np.concatenate(rows_list)
   471         3        278.0     92.7      0.1              cols = np.concatenate(cols_list)
   472         3      33298.0  11099.3     13.8              P_mat = sp.csr_matrix((data, (rows, cols)), shape=(C.K, C.K))
   473                                                   else:
   474                                                       P_mat = sp.csr_matrix((C.K, C.K))
   475                                                       
   476         3         37.0     12.3      0.0          P_sparse_list.append(P_mat)
   477                                           
   478         1          4.0      4.0      0.0      return P_sparse_list

