Timer unit: 1e-09 s

Total time: 0.19158 s
Average time: 0.19158 s
File: /home/gblum/dev/DPOC_Exercise/Solver.py
Function: solution at line 31

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    31                                           def solution(C: Const) -> tuple[np.ndarray, np.ndarray]:
    32         1       3591.0   3591.0      0.0      Total_start = time.perf_counter()
    33                                           
    34         1      23306.0  23306.0      0.0      print("Computing Transition Probabilities... (fast)")
    35         1        733.0    733.0      0.0      T_start_time = time.perf_counter()
    36         1   26708431.0 2.67e+07     13.9      P_list = compute_transition_probabilities_vectorized(C)#compute_transition_probabilities_fast(C)
    37                                           
    38                                               # --- OPTIMIZATION: Pre-Stack P Matrices ---
    39         1     291669.0 291669.0      0.2      P_stack = sp.vstack(P_list).tocsr()
    40                                           
    41         1       3067.0   3067.0      0.0      del P_list
    42                                           
    43         1       1641.0   1641.0      0.0      T_end_time = time.perf_counter()
    44         1       3201.0   3201.0      0.0      K = C.K
    45         1      17671.0  17671.0      0.0      print("Computing Stage Costs...")
    46         1        921.0    921.0      0.0      SC_start_time = time.perf_counter()
    47         1      64643.0  64643.0      0.0      Q = compute_expected_stage_cost_fast(C, K)
    48         1     139787.0 139787.0      0.1      Q = compute_expected_stage_cost(C)
    49         1       1952.0   1952.0      0.0      SC_end_time = time.perf_counter()
    50                                           
    51                                               # --- iGMRES & Solver Parameters ---
    52         1       3853.0   3853.0      0.0      K, L = C.K, C.L
    53         1        781.0    781.0      0.0      gamma = 1.0
    54         1        846.0    846.0      0.0      dtype = np.float64
    55                                           
    56         1       5238.0   5238.0      0.0      J = np.zeros(K, dtype=dtype)
    57         1       2881.0   2881.0      0.0      policy = np.zeros(K, dtype=int)
    58                                           
    59                                               # Tolerances
    60         1        352.0    352.0      0.0      gmres_tol_max = 1e-5
    61         1        385.0    385.0      0.0      gmres_tol_min = 1e-9
    62         1        337.0    337.0      0.0      eta = 0.5
    63         1        228.0    228.0      0.0      outer_tol = 1e-7
    64                                           
    65                                               # Iteration limits
    66         1        289.0    289.0      0.0      max_outer_iters = 200
    67         1        312.0    312.0      0.0      gmres_restart = 60
    68         1        298.0    298.0      0.0      max_inner_iters = 15
    69                                           
    70         1        246.0    246.0      0.0      delta_J_prev = 1.0
    71         1       7136.0   7136.0      0.0      range_k = np.arange(K, dtype=int) # Pre-compute for slicing
    72                                           
    73         1        461.0    461.0      0.0      start_time = time.perf_counter()
    74                                           
    75         1    1781901.0 1.78e+06      0.9      A_all = build_A_fast_setup(K, L, P_stack, gamma, dtype)
    76                                           
    77                                               # Begin iterations
    78        26      22234.0    855.2      0.0      for outer_iter in range(max_outer_iters):
    79        26     182108.0   7004.2      0.1          J_prev = J.copy()
    80                                           
    81                                                   # --- 1. Build A (Optimized) ---
    82                                                   # A_sparse = build_A(K, P_stack, policy, range_k, gamma, dtype)
    83        26   13835252.0 532125.1      7.2          A_sparse = build_A_fast(A_all, K, policy, range_k)
    84                                           
    85                                                   # --- 2. Preconditioner ---
    86        26    3516077.0 135233.7      1.8          M = make_preconditioner(A_sparse, omega=0.8, inner_iters=3, dtype=dtype)
    87                                           
    88                                                   # Right-hand side
    89        26    1965684.0  75603.2      1.0          b = Q[range_k, policy].astype(dtype)
    90                                           
    91                                                   # Adaptive GMRES Tolerance
    92                                                   # If delta_J is large, we don't need a perfect linear solve yet.
    93        26      13682.0    526.2      0.0          if outer_iter > 0:
    94        25      25598.0   1023.9      0.0              tol_k = eta * delta_J_prev
    95                                                   else:
    96         1        795.0    795.0      0.0              tol_k = gmres_tol_max
    97                                           
    98        26      43779.0   1683.8      0.0          tol_k = min(max(tol_k, gmres_tol_min), gmres_tol_max)
    99                                           
   100                                                   # --- 3. Solve Linear System ---
   101        26       7085.0    272.5      0.0          try:
   102        52  132555231.0 2.55e+06     69.2              J_eval, info = spla.gmres(
   103        26       8168.0    314.2      0.0                  A_sparse,
   104        26       6758.0    259.9      0.0                  b,
   105        26       7821.0    300.8      0.0                  x0=J,
   106        26       8315.0    319.8      0.0                  tol=tol_k,
   107        26       6910.0    265.8      0.0                  restart=gmres_restart,
   108        26       6677.0    256.8      0.0                  maxiter=max_inner_iters,
   109        26       5787.0    222.6      0.0                  M=M
   110                                                       )
   111        26      25328.0    974.2      0.0              if info != 0:
   112                                                           J_eval = spla.spsolve(A_sparse, b)
   113                                                   except Exception:
   114                                                       J_eval = spla.spsolve(A_sparse, b)
   115                                           
   116                                                   # --- 4. Policy Improvement (Optimized) ---
   117        26    2782069.0 107002.7      1.5          P_J_all = P_stack.dot(J_eval)
   118                                           
   119        26      84164.0   3237.1      0.0          expected_future_costs = P_J_all.reshape((L, K)).T
   120                                           
   121                                                   # Bellman update
   122        26    2943711.0 113219.7      1.5          Q_J = Q + gamma * expected_future_costs
   123                                           
   124                                                   # Greedy improvement
   125        26    2303075.0  88579.8      1.2          new_policy = np.argmin(Q_J, axis=1)
   126                                           
   127                                                   # Stats
   128        26    1128696.0  43411.4      0.6          policy_changes = np.sum(new_policy != policy)
   129        26     864526.0  33251.0      0.5          delta_J = np.max(np.abs(J_eval - J_prev))
   130                                           
   131        26      13063.0    502.4      0.0          delta_J_prev = delta_J
   132        26      24834.0    955.2      0.0          J = J_eval
   133        26      20757.0    798.3      0.0          policy = new_policy
   134                                           
   135        26      37848.0   1455.7      0.0          if policy_changes == 0 and delta_J < outer_tol:
   136         1      18464.0  18464.0      0.0              print(f"Converged in {outer_iter+1} iterations.")
   137         1        560.0    560.0      0.0              break
   138                                               else:
   139                                                   print("Warning: Max outer iterations reached without convergence.")
   140                                           
   141         1       1775.0   1775.0      0.0      end_time = time.perf_counter()
   142                                           
   143         1        674.0    674.0      0.0      T_TP = T_end_time - T_start_time
   144         1        369.0    369.0      0.0      T_SC = SC_end_time - SC_start_time
   145         1        388.0    388.0      0.0      T_J = end_time - start_time
   146         1        738.0    738.0      0.0      Total_time = time.perf_counter() - Total_start
   147                                           
   148         1       8725.0   8725.0      0.0      print("\n--- Timing Summary (Optimized with Slicing) ---")
   149         1      20029.0  20029.0      0.0      print(f"Transition Probabilities: {T_TP:.6f}s")
   150         1       5399.0   5399.0      0.0      print(f"Stage Costs:              {T_SC:.6f}s")
   151         1       4998.0   4998.0      0.0      print(f"Policy Iteration:         {T_J:.6f}s")
   152         1       5034.0   5034.0      0.0      print(f"Total Runtime:            {Total_time:.6f}s")
   153                                           
   154         1        630.0    630.0      0.0      return J, policy

Total time: 0.0263599 s
Average time: 0.0263599 s
File: /home/gblum/dev/DPOC_Exercise/utils.py
Function: compute_transition_probabilities_vectorized at line 232

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   232                                           def compute_transition_probabilities_vectorized(C):
   233                                               """
   234                                               Fully vectorized calculation of transition probabilities.
   235                                               Strictly adheres to PE_instructions.pdf.
   236                                           
   237                                               Corrections Implemented:
   238                                               1. Vertical Motion: y_{k+1} = y_k + v_k (Uses CURRENT velocity, not next).
   239                                               2. Pipe Logic: Shifts happen first, decrement checks NEW state.
   240                                               3. Spawn Probability: Exact linear ramp formula from PDF.
   241                                               4. m_min Logic: Defaults to M-1 (last pipe) if buffer is full.
   242                                               """
   243                                           
   244                                               # 1. Convert State Space to Matrix
   245                                               # ---------------------------------------------------------
   246         1    3750569.0 3.75e+06     14.2      S_arr = np.array(C.state_space, dtype=np.int32)
   247         1      60982.0  60982.0      0.2      N = S_arr.shape[0]
   248                                           
   249                                               # Columns: Y, V, D[0]...D[M-1], H[0]...H[M-1]
   250         1      13745.0  13745.0      0.1      Y = S_arr[:, 0]
   251         1       3528.0   3528.0      0.0      V = S_arr[:, 1]
   252         1      39531.0  39531.0      0.1      D = S_arr[:, 2 : 2 + C.M]
   253         1       6274.0   6274.0      0.0      H = S_arr[:, 2 + C.M : 2 + 2 * C.M]
   254                                           
   255                                               # 2. Pre-process State Lookup (SearchSorted Trick)
   256                                               # ------------------------------------------------------
   257         1      99985.0  99985.0      0.4      dtype_view = np.dtype((np.void, S_arr.dtype.itemsize * S_arr.shape[1]))
   258         1      24819.0  24819.0      0.1      S_void = np.ascontiguousarray(S_arr).view(dtype_view).ravel()
   259         1    1274663.0 1.27e+06      4.8      sort_order = np.argsort(S_void)
   260         1      75467.0  75467.0      0.3      S_void_sorted = S_void[sort_order]
   261                                           
   262         1       5979.0   5979.0      0.0      def lookup_state_indices(next_states_matrix):
   263                                                   next_void = np.ascontiguousarray(next_states_matrix.astype(np.int32)).view(dtype_view).ravel()
   264                                                   search_indices = np.searchsorted(S_void_sorted, next_void)
   265                                                   search_indices = np.clip(search_indices, 0, N - 1)
   266                                                   found_void = S_void_sorted[search_indices]
   267                                                   valid_mask = (found_void == next_void)
   268                                                   return sort_order[search_indices], valid_mask
   269                                           
   270                                               # 3. Deterministic Pipe Dynamics (Per PDF "Dynamics" section)
   271                                               # -----------------------------------------------------------
   272                                           
   273                                               # A. Collision check
   274                                               # "On collision... transition to a cost-free termination state"
   275                                               # We identify these source states and ensure they generate NO transitions in P
   276                                               # (effectively making them absorbing or exiting the set).
   277         1      12786.0  12786.0      0.0      if C.M > 0:
   278         1       1852.0   1852.0      0.0          gap_tol = (C.G - 1) // 2
   279         1     143974.0 143974.0      0.5          is_collided = (D[:, 0] == 0) & (np.abs(Y - H[:, 0]) > gap_tol)
   280                                               else:
   281                                                   is_collided = np.zeros(N, dtype=bool)
   282                                           
   283         1      52224.0  52224.0      0.2      Hat_D = D.copy()
   284         1      48039.0  48039.0      0.2      Hat_H = H.copy()
   285                                           
   286         1       2242.0   2242.0      0.0      if C.M > 0:
   287                                                   # B. Intermediate Quantities
   288                                                   # Case 1: Passing (d[1]=0, no collision). Logic: Shift indices left.
   289         1      10842.0  10842.0      0.0          mask_passing = (D[:, 0] == 0)
   290                                           
   291         1       1458.0   1458.0      0.0          if C.M > 1:
   292                                                       # Shift indices 2..M to 1..M-1 (Python indices 1..M-1 to 0..M-2)
   293         1      88395.0  88395.0      0.3              Hat_D[mask_passing, :-1] = D[mask_passing, 1:]
   294         1      60450.0  60450.0      0.2              Hat_H[mask_passing, :-1] = H[mask_passing, 1:]
   295                                           
   296                                                   # Set last element to 0 / default height
   297         1      33636.0  33636.0      0.1          Hat_D[mask_passing, C.M-1] = 0
   298         1       3522.0   3522.0      0.0          if len(C.S_h) > 0:
   299         1      42446.0  42446.0      0.2              Hat_H[mask_passing, C.M-1] = C.S_h[0]
   300                                           
   301                                                   # C. Drift Decrement
   302                                                   # For "Normal Drift" (d[1] > 0), hat_d = d - 1.
   303                                                   # For "Passing", hat_d[1] = d[2] - 1.
   304                                                   # Since we already shifted d[2] into position 0 for passing states,
   305                                                   # we simply decrement Hat_D[0] wherever it is > 0.
   306         1       9252.0   9252.0      0.0          mask_dec = (Hat_D[:, 0] > 0)
   307         1     110851.0 110851.0      0.4          Hat_D[mask_dec, 0] -= 1
   308                                           
   309                                               # 4. Spawn Parameter Calculation
   310                                               # -----------------------------------------------
   311         1     198727.0 198727.0      0.8      sum_hat_D = np.sum(Hat_D, axis=1)
   312         1      22358.0  22358.0      0.1      s_values = (C.X - 1) - sum_hat_D
   313                                           
   314                                               # PDF Formula for p_spawn(s) implemented vectorized
   315                                               # s <= Dmin - 1: 0
   316                                               # Dmin <= s <= X - 1: linear ramp
   317                                               # s >= X: 1
   318         1       5622.0   5622.0      0.0      numerator = s_values - (C.D_min - 1)
   319         1       5893.0   5893.0      0.0      denominator = float(C.X - C.D_min)
   320         1      53507.0  53507.0      0.2      p_linear = numerator / denominator
   321         1      29481.0  29481.0      0.1      p_spawn_vec = np.clip(p_linear, 0.0, 1.0)
   322                                           
   323                                               # Find m_min: "smallest index with no assigned obstacle"
   324                                               # Python indices 1..M-1. If none, default to M-1.
   325         1      35372.0  35372.0      0.1      k_spawn_indices = np.full(N, C.M - 1, dtype=int)
   326                                           
   327         1       1700.0   1700.0      0.0      if C.M > 1:
   328         1       1590.0   1590.0      0.0          search_view = Hat_D[:, 1:]
   329         1      13307.0  13307.0      0.1          is_zero_view = (search_view == 0)
   330         1      77810.0  77810.0      0.3          first_zero_rel = np.argmax(is_zero_view, axis=1)
   331         1      31522.0  31522.0      0.1          any_zero_found = np.any(is_zero_view, axis=1)
   332         1      54831.0  54831.0      0.2          k_spawn_indices[any_zero_found] = first_zero_rel[any_zero_found] + 1
   333                                           
   334                                               # 5. Iterate Inputs & Build Matrix
   335                                               # --------------------------------
   336         1       2021.0   2021.0      0.0      prob_h_new = 1.0 / len(C.S_h) if len(C.S_h) > 0 else 0.0
   337         1       7321.0   7321.0      0.0      U_array = np.array(C.input_space)
   338                                           
   339         1       7715.0   7715.0      0.0      P_data = [[] for _ in range(C.L)]
   340         1       3830.0   3830.0      0.0      P_rows = [[] for _ in range(C.L)]
   341         1       2958.0   2958.0      0.0      P_cols = [[] for _ in range(C.L)]
   342                                           
   343         4      16454.0   4113.5      0.1      for l_idx, u in enumerate(U_array):
   344                                                   # Probabilistic Velocities
   345         3       4281.0   1427.0      0.0          if u == C.U_strong:
   346         1       3947.0   3947.0      0.0              W_flap = np.arange(-C.V_dev, C.V_dev + 1)
   347                                                   else:
   348         2       4923.0   2461.5      0.0              W_flap = np.array([0])
   349         3       3219.0   1073.0      0.0          prob_flap = 1.0 / len(W_flap)
   350         3       1375.0    458.3      0.0          n_w = len(W_flap)
   351                                           
   352                                                   # Broadcast V + u + W (Calculates v_{k+1})
   353         3     364074.0 121358.0      1.4          V_next_matrix = V[:, None] + u + W_flap[None, :] - C.g
   354         3     159305.0  53101.7      0.6          V_next_flat = np.clip(V_next_matrix, -C.V_max, C.V_max).flatten()
   355                                           
   356                                                   # Calculate y_{k+1} based on CURRENT velocity v_k (PDF Page 5 formula)
   357                                                   # y_{k+1} = min(max(y_k + v_k, 0), Y-1)
   358                                                   # We repeat Y and V (current) to match the shape of the expanded arrays
   359         3     117241.0  39080.3      0.4          Y_repeated = np.repeat(Y, n_w)
   360         3      78508.0  26169.3      0.3          V_current_repeated = np.repeat(V, n_w)
   361         3     149983.0  49994.3      0.6          Y_next_flat = np.clip(Y_repeated + V_current_repeated, 0, C.Y - 1).astype(np.int32)
   362                                           
   363                                                   # Source filtering (Collided states are dead ends)
   364         3     160405.0  53468.3      0.6          source_idxs = np.repeat(np.arange(N), n_w)
   365         3      85984.0  28661.3      0.3          valid_src = ~np.repeat(is_collided, n_w)
   366                                           
   367         3      49897.0  16632.3      0.2          V_next = V_next_flat[valid_src]
   368         3      44732.0  14910.7      0.2          Y_next = Y_next_flat[valid_src]
   369         3     139822.0  46607.3      0.5          source_idxs = source_idxs[valid_src]
   370                                           
   371                                                   # Get pre-computed pipe params for valid rows
   372         3     472865.0 157621.7      1.8          Hat_D_sub = Hat_D[source_idxs]
   373         3     599546.0 199848.7      2.3          Hat_H_sub = Hat_H[source_idxs]
   374         3     190991.0  63663.7      0.7          p_spawn_sub = p_spawn_vec[source_idxs]
   375         3     152134.0  50711.3      0.6          k_spawn_sub = k_spawn_indices[source_idxs]
   376                                           
   377                                                   # --- Path 1: No Spawn ---
   378         3     145054.0  48351.3      0.6          probs_ns = prob_flap * (1.0 - p_spawn_sub)
   379         3      30607.0  10202.3      0.1          mask_ns = probs_ns > 0
   380                                           
   381         3     110996.0  36998.7      0.4          if np.any(mask_ns):
   382         3    2832686.0 944228.7     10.7              NS_states = np.column_stack((Y_next[mask_ns], V_next[mask_ns], Hat_D_sub[mask_ns], Hat_H_sub[mask_ns]))
   383         3    5341400.0 1.78e+06     20.3              dest_idx, valid = lookup_state_indices(NS_states)
   384                                           
   385         3       2175.0    725.0      0.0              keep = valid
   386         3     133632.0  44544.0      0.5              P_rows[l_idx].append(source_idxs[mask_ns][keep])
   387         3      43131.0  14377.0      0.2              P_cols[l_idx].append(dest_idx[keep])
   388         3     152982.0  50994.0      0.6              P_data[l_idx].append(probs_ns[mask_ns][keep])
   389                                           
   390                                                   # --- Path 2: Spawn ---
   391         3      47365.0  15788.3      0.2          mask_s = (p_spawn_sub > 0)
   392                                           
   393         3     100461.0  33487.0      0.4          if np.any(mask_s) and len(C.S_h) > 0:
   394         3      33629.0  11209.7      0.1              S_Y = Y_next[mask_s]
   395         3      80344.0  26781.3      0.3              S_V = V_next[mask_s]
   396         3     225152.0  75050.7      0.9              S_D = Hat_D_sub[mask_s]
   397         3     214617.0  71539.0      0.8              S_H = Hat_H_sub[mask_s]
   398         3      51085.0  17028.3      0.2              S_k = k_spawn_sub[mask_s]
   399         3      61951.0  20650.3      0.2              S_base_prob = prob_flap * p_spawn_sub[mask_s]
   400                                           
   401                                                       # Calculate s to fill (re-computed for flattened subset)
   402         3     179104.0  59701.3      0.7              S_sum_d = np.sum(S_D, axis=1)
   403         3      61952.0  20650.7      0.2              s_fill = np.clip((C.X - 1) - S_sum_d, C.D_min, C.X - 1)
   404                                           
   405                                                       # Iterate over all possible new heights (uniform prob)
   406        12      17491.0   1457.6      0.1              for h_new in C.S_h:
   407         9      27823.0   3091.4      0.1                  D_new = S_D.copy()
   408         9      18256.0   2028.4      0.1                  H_new = S_H.copy()
   409         9      47067.0   5229.7      0.2                  rows = np.arange(len(S_Y))
   410                                           
   411                                                           # Assign new pipe to the identified slot
   412         9     136139.0  15126.6      0.5                  D_new[rows, S_k] = s_fill
   413         9     129671.0  14407.9      0.5                  H_new[rows, S_k] = h_new
   414                                           
   415         9     580479.0  64497.7      2.2                  S_states = np.column_stack((S_Y, S_V, D_new, H_new))
   416         9    2964465.0 329385.0     11.2                  dest_idx, valid = lookup_state_indices(S_states)
   417                                           
   418         9      15486.0   1720.7      0.1                  keep = valid
   419         9     152575.0  16952.8      0.6                  P_rows[l_idx].append(source_idxs[mask_s][keep])
   420         9      29989.0   3332.1      0.1                  P_cols[l_idx].append(dest_idx[keep])
   421         9      86074.0   9563.8      0.3                  P_data[l_idx].append(S_base_prob[keep] * prob_h_new)
   422                                           
   423                                               # 6. Construct Sparse Matrices
   424         1        496.0    496.0      0.0      P_sparse = []
   425         4       8573.0   2143.2      0.0      for l in range(C.L):
   426         3       2657.0    885.7      0.0          if len(P_data[l]) > 0:
   427         3     149056.0  49685.3      0.6              data = np.concatenate(P_data[l])
   428         3     101668.0  33889.3      0.4              rows = np.concatenate(P_rows[l])
   429         3     125089.0  41696.3      0.5              cols = np.concatenate(P_cols[l])
   430         3    2582231.0 860743.7      9.8              P_l = sp.csr_matrix((data, (rows, cols)), shape=(C.K, C.K))
   431         3       3246.0   1082.0      0.0              P_sparse.append(P_l)
   432                                                   else:
   433                                                       P_sparse.append(sp.csr_matrix((C.K, C.K)))
   434                                           
   435         1        304.0    304.0      0.0      return P_sparse

